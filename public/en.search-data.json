{"/docs/blog/":{"data":{"":"Some description about blog section. Coming from _index.md and can be left emppty or can be used to mention highlights about the latest posts etc."},"title":"Blog"},"/docs/blog/5-best-practices-for-configuring-and-managing-a-load-balancer/":{"data":{"":"","1-monitor-your-servers-closely#1. Monitor Your Servers Closely":"","2-know-your-traffic-patterns#2. Know Your Traffic Patterns":"","3-use-autoscaling-when-possible#3. Use Autoscaling When Possible":"","4-utilize-automated-monitoring-tools#4. Utilize Automated Monitoring Tools":"","5-keep-backup-systems-in-place#5. Keep Backup Systems In Place":"A load balancer is an essential tool in any business’s IT infrastructure. It ensures that traffic is distributed evenly across servers, helping to prevent performance bottlenecks that can lead to outages. As such, it’s important to configure and manage your load balancer correctly. Here are five tips for doing just that. Must Read : 6 Benefits of Deploying a Load Balancer on your server.\n1. Monitor Your Servers Closely To ensure peak performance from your load balancer, you need to monitor the servers it’s connected to. This means monitoring all of the server’s resources (CPU usage, memory utilization, etc.) on a regular basis so that you can quickly identify any potential issues and address them before they cause major problems. 2. Know Your Traffic Patterns Load balancers are most effective when they’re configured according to specific traffic patterns. So, take some time to study the traffic coming into your website or application and adjust your configuration accordingly. Doing so will allow you to optimize your setup for maximum efficiency and minimize potential outages due to unexpected spikes in traffic or other irregularities. 3. Use Autoscaling When Possible Autoscaling is a great way to ensure that your load balancer always has enough capacity to handle incoming traffic without bogging down the system or causing outages due to overloading resources. Not only does it help save on costs by allowing you scale up or down as needed, but it also makes sure that users always have access to the services they need when they need them most. 4. Utilize Automated Monitoring Tools Automated monitoring tools can be used in conjunction with your load balancer configuration in order to detect any issues before they become serious problems and make sure everything is running smoothly at all times. The more data you collect from these tools, the better informed decisions you’ll be able make when it comes time for maintenance or upgrades down the line. 5. Keep Backup Systems In Place Nothing lasts forever, including your load balancer configuration and hardware setup – which is why having backup systems in place is so important! This could mean anything from having multiple failover systems ready in case of an emergency or simply keeping redundant copies of all configurations and settings so that you can quickly restore service should something go wrong with the primary setup. A load balancer can be a powerful tool for managing traffic on your website or application. By following these best practices, you can ensure that your load balancer is properly configured and able to handle the traffic demands of your users. If you do not have a load balancer in place, we recommend considering one as part of your infrastructure."},"title":"5 Best practices for configuring and managing a Load Balancer"},"/docs/blog/5-most-effective-ways-to-avoid-cloud-bill-shocks/":{"data":{"":"","1-establish-a-budget# \u003cstrong\u003e1. Establish a budget:\u003c/strong\u003e":"","2-monitor-usage#\u003cstrong\u003e2. Monitor usage:\u003c/strong\u003e":"","3-use-reserved-instances#\u003cstrong\u003e3. Use reserved instances:\u003c/strong\u003e":"","4-optimize-resources#\u003cstrong\u003e4 .Optimize resources:\u003c/strong\u003e":"","5-search-for-an-alternative#\u003cstrong\u003e5 Search for an alternative:\u003c/strong\u003e ":"Cloud bill shock is a common phenomenon among IT managers, small and medium-sized businesses. A cloud bill shock can arise when an unexpected, large bill arrives from your cloud service provider. It can be an unpleasant surprise that erodes your budget and disrupts operations. But you don’t have to let these shocks derail your business. By following these Five simple strategies, you can avoid the majority of cloud bill shocks and optimize costs in the long run. Most Effective Ways to Avoid Cloud Bill Shocks.\n1. Establish a budget: The first step in avoiding cloud bill shocks is to establish a budget for your cloud services expenditures. Make sure that this budget is realistic, based on past usage and anticipated future needs. This will give you a clear understanding of what you’re willing to spend and help you plan accordingly throughout the year. 2. Monitor usage: Monitoring your usage of cloud services is key to avoiding costly surprises down the line. Investing in tools or services that provide real-time insights into resource utilization can help ensure that you never exceed your allocated budget—and save you money in the long run. 3. Use reserved instances: Reserved instances are pre-purchased contracts that guarantee capacity availability at fixed prices over a specified period of time—often one or three years—from the original purchase date. By taking advantage of such offerings, you can lower costs significantly by locking in discounted rates on commonly used services and resources over extended periods of time. 4 .Optimize resources: Optimizing resources wisely can make a big difference when it comes to managing costs associated with cloud services utilization over time as well as minimizing unexpected bills from month to month.. For example, optimizing storage space by archiving data no longer being used but still needed for reference or compliance purposes could help reduce bills significantly over time . Additionally, shutting down idle virtual machines during low usage times could also greatly reduce costs long term . 5 Search for an alternative: Switching cloud providers can be a daunting task for many business owners, but it can save them from the pain of high bill shocks. When selecting a new cloud provider, one of the most important criteria should be that your provider offers a predictable billing model. With such a model, you will have full control and visibility over your costs, allowing you to create budget plans and cost forecasts more accurately. Additionally, with predictable billing you will know exactly what to expect each month in terms of pricing and will be able to plan accordingly without being subject to sudden changes or unexpected surprises and Microhost is the right cloud provider for this.\nWith careful planning and effective management, it’s possible to avoid most instances of cloud bill shock."},"title":"5 Most Effective Ways to Avoid Cloud Bill Shocks."},"/docs/blog/5-proven-strategies-for-disaster-recovery-and-business-continuity-in-the-cloud/":{"data":{"":"","1backup-and-recovery#\u003cstrong\u003e1.Backup and Recovery\u003c/strong\u003e":"","2-replication#\u003cstrong\u003e2. Replication\u003c/strong\u003e":"","3multi-cloud#\u003cstrong\u003e3.Multi-Cloud\u003c/strong\u003e":"","4high-availability#\u003cstrong\u003e4.High Availability\u003c/strong\u003e":"","5-disaster-recovery-as-a-service-draas#\u003cstrong\u003e5. Disaster Recovery as a Service (DRaaS)\u003c/strong\u003e":"Cloud disaster recovery is more than just backing up your data to a remote server. It requires a holistic approach that encompasses people, processes, and technology. Several key elements can make or break your recovery efforts, from risk assessment to testing and automation. To help you get it right, we’ve compiled a list of 5 proven strategies for disaster recovery and business continuity in the cloud that you can start implementing today. 1.Backup and Recovery The first strategy for disaster recovery and business continuity in the cloud is to implement a regular backup and recovery process for critical data and applications. This involves creating copies of critical data and applications and storing them in a secure cloud environment.\nBy doing this, in an outage, businesses can quickly and easily restore their data and applications from the cloud, minimizing downtime and ensuring business continuity. It is important to test the restoration process regularly to ensure that the data and applications can be recovered quickly and accurately.\nThe cloud provides several advantages for backup and recovery, such as easy scalability, cost-effectiveness, and the ability to store data in different geographic locations for redundancy. This strategy can help businesses to mitigate the risk of data loss and downtime, protecting their reputation and minimizing the impact on customers and partners.\n2. Replication This means creating a copy of critical data and applications in a different location from the primary system. In the cloud, you can replicate data and applications across different regions or availability zones within the same cloud service provider or multiple providers. This ensures that your data and applications remain accessible during an outage in the primary system.\nTo keep the replicated data and applications up to date, cloud-based replication solutions use technologies such as asynchronous data replication and real-time synchronization. As a result, if an outage occurs, you can failover to the replicated data and applications quickly and easily, minimizing the impact on your business and customers.\nImplementing a cloud-based replication solution helps businesses achieve a high level of resilience and disaster recovery capability while minimizing the need for complex and costly backup and restore processes.\n3.Multi-Cloud This means using multiple cloud service providers to ensure redundancy and disaster recovery across different regions and availability zones to minimize the impact of an outage. When relying on a single cloud service provider, businesses risk outages due to natural disasters, system failures, or cyber-attacks that may occur within the provider’s infrastructure. However, businesses can mitigate this risk by using multiple cloud service providers and ensuring that their data and applications remain available and accessible even in an outage in one provider’s infrastructure.\nA multi-cloud strategy also enables businesses to take advantage of different cloud providers’ strengths, such as geographical reach, pricing, and service offerings. It also avoids vendor lock-in, allowing businesses to switch providers and avoid disruptions.\nTo implement a multi-cloud approach, businesses must carefully evaluate the costs and complexities of managing multiple cloud service providers. They must also ensure that their applications are compatible with multiple cloud platforms and have the necessary redundancy and failover mechanisms.\nBusinesses can use a multi-cloud approach to ensure a high level of resilience and disaster recovery capability while minimizing the risk of downtime and data loss during an outage.\n4.High Availability Deploy highly available architectures, such as auto-scaling and load-balancing, to ensure that applications remain available and responsive during an outage.\nAuto-scaling and load-balancing allow applications to adjust dynamically to changes in demand, ensuring that resources are allocated efficiently and that the application remains available and responsive to users. Auto-scaling automatically adds or removes compute resources based on workload demand, while load-balancing distributes traffic across multiple servers to prevent any single server from becoming overloaded.\nIn disaster recovery and business continuity, these techniques can be used to ensure that critical applications are highly available and can handle increased traffic or demand during an outage. For example, suppose an application server fails. Auto-scaling can quickly spin up additional servers to take over the workload, while load-balancing ensures that traffic is routed to the available servers.\nTo implement highly available architectures in the cloud, businesses must design their applications with resilience, including redundancy, failover mechanisms, and fault-tolerant design. They must also monitor their applications to continue identifying and mitigating potential issues before they lead to downtime.\n5. Disaster Recovery as a Service (DRaaS) DRaaS is a cloud-based service that provides businesses with a complete disaster recovery solution. This solution includes backup, replication, and failover, without the need for businesses to invest in their infrastructure.\nBy replicating critical data and applications to a secondary site or cloud environment, DRaaS ensures that systems can quickly fail in an outage or disaster. DRaaS providers often offer a range of service levels, from basic backup and recovery to comprehensive disaster recovery solutions with near-zero recovery time (RTOs) and recovery point objectives (RPOs).\nOne of the key benefits of DRaaS is that it reduces the need for businesses to invest in their disaster recovery infrastructure, which can be costly and complex to manage. DRaaS providers can also help businesses develop and test their disaster recovery plans, ensuring they are fully prepared for a potential disaster.\nTo implement DRaaS, businesses must carefully evaluate their disaster recovery requirements, including their RTOs and RPOs, and choose a provider that meets their specific needs. They must also ensure that their data and applications are compatible with the DRaaS provider’s environment and have a plan for testing and maintaining their disaster recovery solution.\nUsing DRaaS, businesses can ensure a high level of resilience and disaster recovery capability without the need for significant capital investment and complex infrastructure management.\nBy following these strategies, businesses can significantly reduce the risk of data loss and downtime in an outage, ensuring business continuity and minimizing the impact on customers, employees, and partners."},"title":"5 Proven Strategies for Disaster Recovery and Business Continuity in the Cloud"},"/docs/blog/6-benefits-of-deploying-a-load-balancer-on-your-server/":{"data":{"":"","1-improved-scalability#\u003cstrong\u003e1) Improved scalability:\u003c/strong\u003e":"","2-reduced-costs#\u003cstrong\u003e2) Reduced costs:\u003c/strong\u003e":"","3-increased-security#\u003cstrong\u003e3) Increased security:\u003c/strong\u003e":"","4-improved-performance#\u003cstrong\u003e4) Improved performance:\u003c/strong\u003e":"Here we will discuss the benefits of deploying a load balancer on your server and what is a load balancer. A load balancer distributes network or application traffic across a cluster of servers. A load balancer sits between client devices and backend servers, receiving and then routing requests to the appropriate server.\nThe main benefit of using a load balancer is improved availability and performance. By balancing traffic across multiple servers, a load balancer helps ensure that no single server is overwhelmed by requests and that all servers are available to handle client requests.\nBenefits of using a Load Balancer\nOther Benefits of using a load balancer include the following: 1) Improved scalability: By distributing traffic across multiple servers, a load balancer makes it possible to scale up your infrastructure to accommodate increased traffic without overburdening any single server.\n2) Reduced costs: You can reduce your overall hosting costs by using multiple lower-powered servers instead of a single, more powerful server.\n3) Increased security: By sitting between client devices and backend servers, a load balancer can act as a “gateway” through which all traffic must pass. This makes it possible to implement security measures such as firewalls and intrusion detection/prevention systems (IDS/IPS) that can help protect your backend servers from attacks.\n4) Improved performance: By balancing traffic across multiple servers, a load balancer helps to ensure that no single server is overwhelmed by requests. This can lead to faster response times for clients and reduced latency.","5-better-utilization-of-resources#5) Better utilization of resources:":"By using multiple lower-powered servers instead of a single, more powerful server, you can better utilize each server’s processing power and memory. This can lead to improved performance for your applications.","6-flexibility#6) Flexibility:":"Load balancers can be used with on-premises infrastructure or in the cloud, allowing you to scale up or down as needed without making significant changes to your infrastructure. There are many Benefits of Deploying a Load Balancer that can improve the availability, performance, scalability, security, and utilization of your applications and infrastructure. Microhost’s load balancers are easy to deploy, just like our cloud servers, and are ready to use the moment they are deployed. If you don’t already have one, consider deploying one today.","other-benefits-of-using-a-load-balancer-include-the-following#Other Benefits of using a load balancer include the following:":""},"title":"6 Benefits of Deploying a Load Balancer on your server."},"/docs/blog/6-cloud-computing-myths-busted/":{"data":{"":"","1-myth-the-cloud-is-expensive#\u003cstrong\u003e1. Myth: The cloud is expensive.\u003c/strong\u003e":"","2-myth-the-cloud-is-unreliable#\u003cstrong\u003e2. Myth: The cloud is unreliable.\u003c/strong\u003e":"","3-myth-the-cloud-is-insecure#\u003cstrong\u003e3. Myth: The cloud is insecure.\u003c/strong\u003e ":"","4-myth-the-cloud-is-complicated#\u003cstrong\u003e4. Myth: The cloud is complicated.\u003c/strong\u003e ":"","5-myth-the-cloud-is-only-for-big-businesses#\u003cstrong\u003e5. Myth: The cloud is only for big businesses.\u003c/strong\u003e ":"","6-myth-the-cloud-is-only-for-storage#\u003cstrong\u003e6. Myth: The cloud is only for storage.\u003c/strong\u003e ":"There’s a lot of misinformation out there about cloud computing. We’re here to set the record straight and bust some of the most common cloud computing myths!\nWhat is cloud computing? Before busting the myths, let’s understand what cloud computing is! Cloud computing delivers servers, storage, databases, networking, software, analytics, and intelligence services over the Internet (“the cloud”) to offer faster innovation, flexible resources, and economies of scale. With cloud computing, businesses can avoid the upfront investment in hardware and software infrastructure and instead pay for only the resources they use on a pay-as-you-go basis. This flexibility enables organizations to respond quickly to changing business needs while controlling IT costs. In addition, cloud services can be scaled up or down as needed without extensive planning or reengineering. The myths of cloud computing. most common cloud computing myths\n1. Myth: The cloud is expensive. Busted! Moving to the cloud can save your business money in the long run. With on-premise infrastructure, you must pay for power, cooling, and physical space to house your servers. With the cloud, you only pay for the resources you use. Plus, you don’t have to worry about upkeep and maintenance costs.\n2. Myth: The cloud is unreliable. Busted! Cloud providers invest heavily in ensuring that their data centers are reliable and always available. Clouds are often more reliable than on-premise infrastructure because they have built-in redundancy mechanisms. For example, if one data center goes down, your cloud provider can quickly spin up another to take its place.\n3. Myth: The cloud is insecure. Busted! Cloud providers go to great lengths to secure their data centers and keep customer data safe. They have teams of security experts who constantly monitor for threats and implement new security measures as needed. Plus, the data stored in the cloud is typically encrypted, making it even more difficult for hackers to access.\n4. Myth: The cloud is complicated. Busted! Cloud providers offer a variety of tools and resources to help customers get started with the cloud and make the most of its features. Plus, many providers offer 24/7 support if you encounter any technical issues. 5. Myth: The cloud is only for big businesses. Busted! While enterprises are certainly embracing the cloud, it’s also being used by small businesses and individuals who need a simple, cost-effective way to store and share data online. 6. Myth: The cloud is only for storage. Busted! While storage is one of the most popular uses for the cloud, it’s far from the only use case. Many businesses rely on the cloud for computing resources, application hosting, data analysis, etc. Conclusion: Moving to the cloud can be beneficial for your business in terms of costs, reliability, performance, scalability, and security. Don’t let myths about the cloud stop you from exploring what it can do for your organization. Microhost provides top-notch cloud computing services. The best part is that you can try it out for seven days without risk.","the-myths-of-cloud-computing#\u003cstrong\u003eThe myths of cloud computing.\u003c/strong\u003e":"","what-is-cloud-computing#\u003cstrong\u003eWhat is cloud computing?\u003c/strong\u003e ":""},"title":"6 Cloud Computing Myths, Busted!"},"/docs/blog/7-reasons-why-cloud-infrastructure-is-important-for-startups/":{"data":{"":"","1-scalability#\u003cstrong\u003e1. Scalability\u003c/strong\u003e":"","2-flexibility#\u003cstrong\u003e2. Flexibility\u003c/strong\u003e":"","3-reliability#\u003cstrong\u003e3. Reliability\u003c/strong\u003e":"","4-cloud-infrastructure-is-cost-effective#\u003cstrong\u003e4. Cloud infrastructure\u003c/strong\u003e \u003cstrong\u003eis Cost-effective\u003c/strong\u003e":"","5-security#\u003cstrong\u003e5. Security\u003c/strong\u003e":"","6-compliance#\u003cstrong\u003e6. Compliance\u003c/strong\u003e":"","7-support#\u003cstrong\u003e7. Support\u003c/strong\u003e":"Cloud Infrastructure is Important for Startups, and many factors contribute to a startup’s success; one of the most important is having a strong infrastructure. Have you ever wondered why some startups succeed while others fail?\nThat’s where cloud infrastructure comes in. Cloud infrastructure can provide startups with the scalability, flexibility, and reliability they need to grow and thrive. Here are seven reasons why cloud infrastructure is so important for startups:\nAdvantages of cloud infrastructure for startups\n1. Scalability One of the biggest challenges for startups is predicting future growth. Will your user base double in the next six months? What about next year? Trying to forecast that kind of growth can be difficult, and if you underestimate it, you could end up with an infrastructure that can’t handle the demand.\nWith cloud infrastructure, you only pay for the resources you use, so it’s easy to scale up or down as your needs change. That gives you the flexibility to respond quickly to changes in user demand, without having to over-provision your infrastructure and waste money on unused resources.\n2. Flexibility Another challenge for startups is the need to be agile and respond quickly to changes in the market. With a traditional infrastructure, it can take weeks or even months to provision new resources or make changes to your existing setup. That’s not ideal when you need to move fast to stay ahead of the competition.\nCloud infrastructure provides the flexibility you need to make changes quickly and easily. If you need to add new servers or storage, you can do it in minutes instead of weeks. And if you need to reduce your capacity, you can do that just as easily. That means you can respond quickly to changes in the market and keep your startup agile.\n3. Reliability Startups need to be able to rely on their infrastructure to keep their business running smoothly. Downtime can cost you money, so it’s important to have an infrastructure that is reliable and always available.\nWith cloud infrastructure, you can take advantage of the same high-availability features that are used by some of the largest companies in the world. That means your startup can have the same level of reliability and availability, without having to invest in expensive hardware and software.\n4. Cloud infrastructure is Cost-effective A traditional infrastructure can be costly to set up and maintain. Startups often don’t have the capital to invest in their own data center, so they have to lease space from a third-party provider. That can be expensive, and it can limit the amount of control you have over your infrastructure.\nWith cloud infrastructure, you only pay for the resources you use, so it’s more cost-effective than a traditional infrastructure. And because you don’t have to invest in your own data center, you can use that money to invest in other areas of your business.\n5. Security Startups need to be able to protect their data and applications from cyberattacks. With a traditional infrastructure, you have to manage your own security, which can be a challenge if you don’t have the resources or expertise.\nWith cloud infrastructure, you can take advantage of the security features that are provided by the provider. That means you don’t have to worry about managing your own security, and you can focus on other aspects of your business.\n6. Compliance Startups need to be able to comply with industry regulations. With a traditional infrastructure, you have to manage your own compliance, which can be a challenge if you’re not familiar with the regulations.\nWith cloud infrastructure, you can take advantage of the compliance features that are provided by the provider. That means you don’t have to worry about managing your own compliance, and you can focus on other aspects of your business.\n7. Support When you’re running a startup, you need to be able to get help when you need it. With a traditional infrastructure, you have to manage your own support, which can be a challenge if you’re not familiar with the technology.\nWith cloud infrastructure, you can take advantage of the support that is provided by the provider. That means you don’t have to worry about managing your own support, and you can focus on other aspects of your business.\nMicrohost is a cloud infrastructure provider that offers all of these features to startups. We make it easy for startups to get started with cloud infrastructure, and we offer the tools and resources they need to be successful. Contact us to learn more about how we can help your startup."},"title":"7 Reasons Why Cloud Infrastructure is Important for Startups"},"/docs/dns/how-to-configure-bind-as-a-private-network-dns-server-on-centos-7/":{"data":{"":"A DNS or Domain Name System is a distributed database, allows the association of zone records, for example, IP addresses with domain names. If a computer, like your laptop or phone, has to communicate over the internet, they use each other IP addresses with a remote computer, like a web server. People don’t remember IP addresses very well, but they remember the words and phrases in domain names well. Domain names can be used by the DNS system when interfacing with the computer, but computers can still use IP addresses when communicating with each other.\nIn this guide we examine how a DNS server that is the authoritative DNS server for your domain names can be installed and configured. This allows you to fully control your DNS and immediately modify your DNS records whenever you need to do so.","configuration-of-zone-file#Configuration of Zone file":" [root@Microhost]# vi /var/named/forward.example.com You can use the below content as the template.\n$TTL 1d @ IN SOA dns1.example.com. hostmaster.example.com. ( 1 ; serial 6h ; refresh after 6 hours 1h ; retry after 1 hour 1w ; expire after 1 week 1d ) ; minimum TTL of 1 day ; ; ;Name Server Information @ IN NS ns1.example.com. ns1 IN A 198.51.100.10 ; ; ;Mail Server Information example.com. IN MX 10 mail.example.com. mail IN A 198.51.100.20 ; ; ;Additional A Records: www IN A 198.51.100.30 site IN A 198.51.100.30 ; ; ;Additional CNAME Records: slave IN CNAME www.example.com. [ht_message mstyle=“alert” title=“NOTE” \" show_icon=“true” id=\"\" class=““style=”” ]Whenever you will use the domain name in the zone file always use . dot sign at the end of domain name.[/ht_message]\nYou can modify or add the records according to your requirements using the above template.\nThis line means:\n@ – The domain of the file named.conf.local, i.e. example.com, will replace this. IN – INTERNET type records in this case. SOA – The Start Of Authority record is the record. For this domain this is the authoritative record. dns1.example.com. – the DNS record nameserver. – The name server. hostmaster.example.com. – the name server manager’s email address. The @ symbol is substituted by a dot. A reverse zone file must be created. Open the text editor and create the file:\n[root@Microhost]# vi /var/named/reverse.example.com $TTL 1d @ IN SOA dns1.example.com. hostmaster.example.com. ( 1 ; serial 6h ; refresh after 6 hours 1h ; retry after 1 hour 1w ; expire after 1 week 1d ) ; minimum TTL of 1 day ; ; ;Name Server Information @ IN NS ns1.example.com. ns1 IN A 198.51.100.10 ; ; ;Reverse IP Information 10.100.51.198.in-addr.arpa. IN PTR ns1.example.com. 20.100.51.198.in-addr.arpa. IN PTR mail.example.com. 30.100.51.198.in-addr.arpa. IN PTR www.example.com. You can use the above file content as the template according to your requirement .\nWe can check the zone file configuration error using the following command.\nBIND provides two tools to ensure that its configuration files have no errors preventing BIND from starting. The first checks the global settings files and uses the following:\n[root@Microhost]# named-checkconf /etc/named.conf For the second tool use the below command.\n[root@Microhost]# named-checkzone (DOMAIN-NAME) (ZONE-FILE) ","configure-systemd-to-keep-dns-server-running#Configure Systemd To Keep Dns Server Running":"Make a copy of the system service BIND file which we are going to edit.\n[root@Microhost]#cp /lib/systemd/system/named.service /etc/systemd/system/ In future system updates, this guarantees that the edits are not lost. Then, in an editor, open the file:\n[root@Microhost]#vi /etc/systemd/system/named.service Add the given lines into the file.\nRestart=always RestartSec=3 Reload the system daemon file and restart the Dns server.\n[root@Microhost]#systemctl daemon-reload [root@Microhost]#systemctl restart named.service We have completed the installation of BIND DNS SERVER.\nThank You :)","global-bind-settings#Global BIND Settings":"BIND functioning as a DNS server is divided into two sections. The first is to define the global parameters to make BIND work as we want. The second step is to create the domain-based DNS data to be used by BIND. This is called “area information” or “area records.”\nThe global parameters are configured in this section.\nIn /etc/named.conf we are going to edit the first configuration file and configure how bind works. Open your favorite text editor for this file.\n[root@Microhost]# vi /etc/named.conf Add the below line while editing the domain name according to your requirement at the bottom of the file.\nzone \"exmaple.com\" { type master; file \"/var/named/forward.example.com\"; }; zone \"10.100.51.198.in-addr.arpa\" { type master; file \"/var/named/everse.example.com\"; }; The following lines are used in this file:\nzone – this is the domain name or IP address for which BIND responds to requests. Type master – BIND reads the local storage zone information and provides the relevant domain information for the zone line. File – the zone information file. Two sections have the same syntax as you can see in this file. The first section contains the domain name example.com known as the forward DNS record. This means that domain information is converted to IP addresses.\nThe second latter is the server IP address’ reverse dns or PTR record. This turns the other way round, i.e. Domain name to IP addresses. The reverse record zone line looks a bit odd, since the IP address is in reverse. The IP address of 198.51.100.10, which forms the reverse record.\nInverse records are important as many safety systems, such as spam filters, are less likely to accept e-mails sent from a non-reverse IP address.\nNow that the global setup of BIND is set, the area files can be created that hold the DNS information forward and reverse.","installation-of-dns-server#Installation of DNS Server":"This guide is used for BIND’s DNS server. BIND is one of the most used and oldest online DNS servers.\nYou should make sure your server updates the latest packages before installing BIND:\n[root@Microhost]# yum update -y The Debian repositories default for BIND are available and will be installed as follows:\n[root@Microhost]# yum install bind bind-utils Bind is now installed on the server.","prerequisites#Prerequisites":"Before starting please follow the below instructions.\nA CentOS 7 server. A domain name. Root or sudo enabled user on the server. "},"title":"How To Configure BIND as a Private Network DNS Server on CentOS 7"},"/docs/dns/how-to-install-and-configure-powerdns-on-centos-7-using-mariadb/":{"data":{"":"PowerDNS is a DNS server that works on many derivatives from Linux / Unix. It can be configured with various backends, including zone files of the BIND style, relational databases and failover / load balancing. The DNS recurrent can also be set up as part of a separate server process.\nPowerDNS Authoritative server’s latest version is 3.4.4 but 3.4.3 is currently available in the EPEL. In order to test this version for CentOS and Fedora, I would recommend installing the version for the EPEL repository. You can also update PowerDNS easily in the future in this way.\nThis article will present you with the MariaDB backend and PowerAdmin-a usable PowerDNS web interface management tool-how you can install and configure the master PowerDNS-Server.","installing-powerdns-with-mariadb-backend#Installing PowerDNS with MariaDB Backend":"You must first allow your server to simply use the EPEL repository :\n[root@Microhost]# yum install epel-release.noarch Installing the MariaDB Server is the next step. The following command can be easily executed:\n[root@Microhost]# yum -y install mariadb-server mariadb We will configure Mysql as it should be up at system boot time.\n[root@Microhost]# systemctl enable mariadb.service [root@Microhost]# systemctl start mariadb.service We will execute the secure installation for MariaDB password configuration as following:\n[root@Microhost]# mysql_secure_installation /bin/mysql_secure_installation: line 379: find_mysql_client: In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): Press ENTER OK, successfully used password, moving on… Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] y New password: ← Set New Password Re-enter new password: ← Repeat Above Password Password updated successfully! Reloading privilege tables.. … Success! By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] y ← Enter “y” to disable that user … Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] n ← Enter “n” for no … skipping. By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] y ← Enter “y” for yes - Dropping test database… … Success! - Removing privileges on test database… … Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] y ← Enter “y” for yes … Success! Cleaning up… All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! Now MariaDB configuration has been completed. We will proceed for the installation of PowerDNS:\n[root@Microhost]# yum -y install pdns pdns-backend-mysql The PowerDNS configuration file lists /etc/pdns/pdns, but a MySQL database for PowerDNS service is configured before editing. We first log on to the MySQL server and build a powerdns named database:\n[root@Microhost]# # mysql -u root -p MariaDB [(none)]\u003e CREATE DATABASE powerdns; Now we create the database user as following:\nMariaDB [(none)]\u003e GRANT ALL ON powerdns.* TO 'powerdns'@'localhost' IDENTIFIED BY 'COMPLX_Password'; MariaDB [(none)]\u003e GRANT ALL ON powerdns.* TO 'powerdns'@'centos7.localdomain' IDENTIFIED BY 'COMPLX_Password'; MariaDB [(none)]\u003e FLUSH PRIVILEGES; Replace COMPLEX_Password with your password:\nWe will create database tables which will be used in future by powerdns:\nMMariaDB [(none)]\u003e USE powerdns; MariaDB [(none)]\u003e CREATE TABLE domains ( id INT auto_increment, name VARCHAR(255) NOT NULL, master VARCHAR(128) DEFAULT NULL, last_check INT DEFAULT NULL, type VARCHAR(6) NOT NULL, notified_serial INT DEFAULT NULL, account VARCHAR(40) DEFAULT NULL, primary key (id) ); MariaDB [(none)]\u003e CREATE UNIQUE INDEX name_index ON domains(name); MariaDB [(none)]\u003e CREATE TABLE records ( id INT auto_increment, domain_id INT DEFAULT NULL, name VARCHAR(255) DEFAULT NULL, type VARCHAR(6) DEFAULT NULL, content VARCHAR(255) DEFAULT NULL, ttl INT DEFAULT NULL, prio INT DEFAULT NULL, change_date INT DEFAULT NULL, primary key(id) ); MariaDB [(none)]\u003e CREATE INDEX rec_name_index ON records(name); MariaDB [(none)]\u003e CREATE INDEX nametype_index ON records(name,type); MariaDB [(none)]\u003e CREATE INDEX domain_id ON records(domain_id); MariaDB [(none)]\u003e CREATE TABLE supermasters ( ip VARCHAR(25) NOT NULL, nameserver VARCHAR(255) NOT NULL, account VARCHAR(40) DEFAULT NULL ); Now exit from Mysql:\nMariaDB [(none)]\u003e quit; We can finally configure our PowerDNS so that it uses MySQL as a backend.\nOpen the configuration file of PowerDNS located at:\nvi /etc/pdns/pdns.conf It will look like:\n################################# launch Which backends to launch and order to query them in\nlaunch=\nCopy the below codes and put at the end of the file: launch=gmysql gmysql-host=localhost gmysql-user=powerdns gmysql-password=COMPLEX_Password gmysql-dbname=powerdns\nThe password \"COMPLEX\\_Password\" should be the same as previous one. Save the file with **:wq** and exit from the text editor. Now we will start and enable the service of Powerdns as following: [root@Microhost]# systemctl enable pdns.service\n[root@Microhost]# systemctl start pdns.service\n## Installing PowerAdmin console to Manage PowerDNS PowerAdmin – a friendly Web interface designed to manage PowerDNS servers, is now being installed. We have to install PHP and a web server (Apache) because it is written in PHP. [root@Microhost]# yum install httpd php php-devel php-gd php-imap php-ldap php-mysql php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-mhash gettext\nTwo PEAR packages are also required for PowerAdmin: [root@Microhost]# yum -y install php-pear-DB php-pear-MDB2-Driver-mysql\nAfter the installation has been completed, Apache is started and set to start when the system boots: [root@Microhost]# systemctl enable httpd.service\n[root@Microhost]# systemctl start httpd.service\nWe can proceed and download the package of poweradmin console now that all the system requirements for PowerAdmin are done. Since /var/www/html is Apache's default web directory, the package will be downloaded there. [root@Microhost]# cd /var/www/html/\nNow we will download the packages using Wget as following [root@Microhost]# wget http://downloads.sourceforge.net/project/poweradmin/poweradmin-2.1.7.tgz\nZip file has been downloaded now. We have to extract the zip file as following: [root@Microhost]# tar xfv poweradmin-2.1.7.tgz\nNow we will rename the directory name as poweradmin as following: [root@Microhost]# mv poweradmin-2.1.7.tgz poweradmin\nWe can now launch PowerAdmin's web installer while accessing the URL: http://IP\\_address/poweradmin/install/ The output will be shown as below: ![](images/power-1.png) The above page requires you to select the PowerAdmin language. Choose the one you want and then click on the 'Go To Step 2'. The output will be shown as below: The installer expects that you have already created the PowerDNS . ![](images/power2.png) We can move on to the next step since we have already created one. The database details you set up earlier, will be requested. Poweradmin administrator password is also necessary: ![](images/power3.png) Go to step 4 once you've entered them. You are going to create a new user with limited Poweradmin rights. You will have to enter the following fields: - Username - PowerAdmin username. - Password – The user's password. - Hostmaster – This value will be used when you create SOA records and do not have the hostmaster specified. - Primary name server- The value will be used to create new DNS zones as primary name server. - Secondary name server – The value is used to generate new DNS zones as the primary name server. ![](images/power-4.png) The next step will be to ask Poweradmin to create a new user database with limited rights in database tables. The code you need to put in a MySQL console is given below: ![](images/power-6.png) Now login to MySQL database on server using below command: [root@Microhost]# mysql -u root -p\nNow execute the code provided by the Poweadin console: [root@Microhost]# MariaDB [(none)]\u003e GRANT SELECT, INSERT, UPDATE, DELETE ON powerdns.* TO ‘powermarin’@’localhost’ IDENTIFIED BY ‘123qweasd’;\n![](images/power-5.png) Now go to redirect to the path **/var/www/html/poweradmin/inc**. We have to create a file named **config.inc.php** using below command: [root@Microhost]# vi /var/www/html/poweradmin/inc/config.inc.php\n![](images/power-7.png) Now copy all the content of above mentioned image and paste it to file **config.inc.php** Go to the last page where the installation has been finished and you will receive information on accessing the installation of your Poweradmin. ![](images/power-8.png) URLs of other DNS providers can be activated by execution. [root@Microhost]# cp install/htaccess.dist .htaccess\nIt is important to rename or remove the install directory from the poweradmin folder: [root@Microhost]# mv /var/www/html/poweradmin/install/ /var/www/html/poweradmin/donotinstall/\nNow configuration has been successfully completed. We can access the Poweradmin using Url: http://IP_address/poweradmin/\n![](images/power9.png) After login, you can see the main page as following ![](images/mainpage.png) Now you can proceed to add Master Zone as per your requirement. Thank You :) "},"title":"How to Install and Configure PowerDNS on centos 7 using MariaDB."},"/docs/getting_started/":{"data":{"":"","explore-more#Explore More":"Dive deeper into the features and functionalities of Utho by exploring our documentation. You’ll find detailed articles on a wide range of topics, including:\nUser Guide: Learn how to maximize your use of Utho with this comprehensive guide. API Reference: Developers can find detailed information about our API endpoints, including request examples and response formats. FAQ: Find answers to frequently asked questions about Utho. ","getting-started#Getting Started":"For those new to Utho, we recommend starting with our Getting Started guide, which covers the basics of setting up your account and navigating the platform.","stay-updated#Stay Updated":"Our documentation is regularly updated with the latest information on new features, improvements, and fixes. Be sure to check back often to stay informed about the latest developments.\nExplore the Documentation\nThank you for choosing Utho. We’re excited to support you on your journey!","welcome-to-uthos-documentation#Welcome to Utho\u0026rsquo;s Documentation":"Welcome to Utho’s Documentation Welcome to the official documentation for Utho, your go-to resource for all information related to our platform. Here, you’ll find comprehensive guides, tutorials, and reference materials to help you get the most out of Utho.\nWhether you’re a new user looking to get started or an experienced user seeking advanced features, our documentation is designed to provide you with the information you need."},"title":"Getting Started"},"/docs/linux/2-methods-for-re-running-last-executed-commands-in-linux/":{"data":{"":"\nDescription\nThe command history is one of the most useful aspects of the Bash shell. This feature logs all of the commands that a user executes and keeps them in a file located in the user’s home directory (usually /home/$USER/.bash history). This makes it simple for the user to recall, amend, and perform previously executed instructions again.\nIn this piece, we will illustrate how to re-execute a particular command by retrieving it from the history of commands that have been input into a shell. This allows you to avoid repeatedly inputting the same commands, which is a helpful feature.\nIn a normal situation, you can utilise the Up arrow keys to recover a previous command in order to acquire a command that you just ran lately. Maintaining consistent pressure on it will cycle through many commands in the history, allowing you to locate the one you want more quickly. To move in the other direction, use the Down arrow on your keyboard.\nYou can use the history command if you want to re-execute a certain command from the history of commands. However, the history file may contain a lot of entries.\n# history The next step is to obtain the number(s) of the command(s) you wish to re-execute. For instance, if you want to start httpd and inspect its status, you will need to re-execute the instructions 104 and 105, as shown.\n# !104 # 105 You can also re-execute a command that you have already used (for example, sudo yum update) by using the ‘!’ character followed by a few of the first characters (for example, sud or sudo) of that particular command, as demonstrated here.\n# !sud or\n# !sudo The command history, stored in /home/$USER/.bash history, is one of Bash’s best features. The user may simply recall, amend, and rerun past commands.\nWe’ll show you how to rerun a shell command in this article. To prevent inputting the same commands, this is beneficial.\nUse the Up arrow keys to retrieve a recent command. To find the command you want, press it again. Reverse with the Down arrow.\nTo re-execute a specific command from the history file, run the history command.\nThank You"},"title":"2 Methods for Re-Running Last Executed Commands in Linux"},"/docs/linux/4-effective-ways-to-determine-the-name-of-a-plugged-usb-device-in-linux/":{"data":{"":"\nDescription\nIn this article we will learn 4 Effective Ways to Determine the Name of a Plugged USB Device in Linux.\nOne of the many aspects of Linux that you should become proficient in as a beginner is the identification of devices that are connected to your computer. It could be the hard disc in your computer, an external hard drive, or another type of portable media like a USB drive or an SD Memory card.\nThe use of USB drives for the transfer of files is extremely common in today’s world. For those (new Linux users) who prefer to work from the command line, becoming familiar with the various methods by which a USB device name can be identified is very important when it comes time to format the device.\nAfter you have connected a device to your computer, such as a USB drive, particularly on a desktop computer, the device is automatically mounted to a specific directory, which is typically located under /media/username/device-label. You are then able to access the files contained within the device by navigating to the directory in which it is mounted. On the other hand, this is not the case while working with a server, since you will need to manually mount a device and then designate where it should be mounted.\nThe /dev directory houses specialised device files that are used by Linux to determine the identity of hardware. This directory contains a number of files, one of which is /dev/sda or /dev/hda, which represents your first master drive. Each partition will be represented by a number, such as /dev/sda1 or /dev/hda1 for the first partition, and so on for subsequent partitions.\nFollow the below steps to learn 4 Effective Ways to Determine the Name of a Plugged USB Device in Linux..","determine-the-name-of-the-usb-device-using-the-fdisk-utility#Determine the Name of the USB Device Using the fdisk Utility":"It is possible to execute fdisk with root privileges in the following manner: fdisk is a powerful application that prints out the partition table on all of your block devices, including USB drives.\n# sudo fdisk -l ","find-disk#Find Disk":" # ls /dev/vda* or\n# ls /dev* Now, let’s find out the names of the devices by utilising a variety of command-line tools, as indicated below:","find-the-name-of-a-usb-device-with-the-lsblk-command#Find the Name of a USB Device with the lsblk Command":"You can also use the lsblk command, which stands for “list block devices.” This command will list all block devices that are currently connected to your system in the following format:\n# lsblk ","using-the-df-command-get-the-name-of-the-connected-usb-device#Using the df command, get the name of the connected USB device":"The df programme, which analyses the consumption of disc space in Linux systems, can be used, as demonstrated in the following image, to view each device that is connected to your computer as well as its mount point:\n# df -h ","using-the-dmesg-command-determine-the-name-of-the-usb-device#Using the dmesg Command, Determine the Name of the USB Device":"A crucial command, dmesg, prints or controls the kernel ring buffer, a data structure that holds information about the activities of the kernel.\nTo read kernel operation messages, run the command that is listed below. This command will also output information about your USB device:\n# dmesg In this post, we have discussed various strategies for determining the name of a USB device using the command line, and that will be all we cover for the time being.\nI really expect that you have a complete understanding of all of the steps. 4 Effective Ways to Determine the Name of a Plugged USB Device in Linux\nMust read :- https://utho.com/docs/tutorial/how-to-create-encrypt-and-decrypt-random-passwords-in-linux/\nThank You"},"title":"4 Effective Ways to Determine the Name of a Plugged USB Device in Linux"},"/docs/linux/access-linux-server-using-ssh-in-windows-linux-and-mac-os/":{"data":{"":"","part-1-access-linux-server-using-ssh-in-windows#Part 1: Access Linux server using SSH in Windows":"","part-2-access-linux-server-using-ssh-in-linux-ubuntu#Part 2: Access Linux server using SSH in Linux Ubuntu":"","ssh-usernameyourserverexamplecom#ssh \u003ca href=\"mailto:username@yourserver.example.com\"\u003eusername@yourserver.example.com\u003c/a\u003e":"\nPart 1: Access Linux server using SSH in Windows 1. Download PuTTY or another PuTTY download source from URL https://the.earth.li/~sgtatham/putty/latest/w64/putty.exe . The file called “putty.exe” is perfect for simple SSH.\n2. Save and download software in your Windows system.\n3. To launch the application, double-click the putty.exe file.\n4. Enter the settings of your connection\nEnter the server ip address or hostname. Port: 22 ( leave as default if SSH port is default) Connection Type: SSH (leave as default) 5. Click Open to start the SSH session.\n6. If this is the first time you are connecting to the server on this computer, you will see the following output. Please accept the connection by clicking Yes.\n7. Once the SSH Connection has been opened, you should see the terminal prompt asking for your username:\nConnect to your preferred SSH user.\n8. Next, please enter your password. Please note that you will NOT see your cursor moving or any typed characters (such as * * * * * *) when you type your password. This is a standard security feature of the PUTTY. Hit get in.\nroot@yourserver.example.com's password: 9. You are logged in to your SSH server now. You will see output like this.\nroot@yourserver.example.com’s password:\nLast failed login: Sat Apr 25 17:03:02 IST 2020 from IP on ssh:notty\nThere were 2 failed login attempts since the last successful login.\nLast login: Sat Apr 25 16:57:08 2020 from IP\n[root@yourserver.example.com ~]\nPart 2: Access Linux server using SSH in Linux Ubuntu 1. If you have ubuntu desktop. Go to Search bar and type “Terminal”.\n2. Now terminal will open and you need to enter the following command on terminal.\n# ssh username@yourserver.example.com 3. You need to enter the password of SSH user of your server. ``` username@yourserver.example.com’s password:\n4\\. Now you have connected your linux server on your ubuntu desktop using terminal and you will get outpout like this: [root@yourserver.example.com ~]#\n## Part 2: Access Linux server using SSH in Mac OS 1\\. If you have Mac OS. Go to Search bar and type \"Terminal\". ![](images/mac-1.png) 2\\. Now terminal will open and you need to enter following command on terminal. ![](images/mac-2.png) ssh username@yourserver.example.com 3\\. You need to enter the password of SSH user of your server. ``` username@yourserver.example.com's password: 4. Now you have connected your linux server on your Mac OS using terminal and you will get outpout like this:\n[root@yourserver.example.com ~]# Thank you…"},"title":"How to access Linux server using SSH in Windows, Linux and Mac OS."},"/docs/linux/add-or-delete-domains-and-subdomain-in-plesk/":{"data":{"":"\nIntoroduction\nIn this article you will know How to ADD OR DELETE DOMAINS AND SUBDOMAIN IN PLESK,\nDomain=The word “domain” may be used to refer to the structure of the internet, which is unique to the world wide web. Domain can also be used to refer to the manner in which an organization’s network resources are arranged. In general, a domain may be thought of as either a sphere of knowledge or an area of control.\nSubdomain: Subdomains are the components of a domain that appear before the primary domain name and the extension of the domain. They can assist you in the organisation of your website. For instance, you may visit docs.themeisle.com. The subdomain that is represented by this URL is docs.\n1.click on the website and domains\n2.Add domain\n3.Fill out the data fields with information regarding the domain you wish to add.\n*On the left-hand menu click website and domains\n*After that, select the “Add Domain” option that is seen in the following screenshot.\n*Select Temporary domain name or Registered domain name\n*Fill out the data fields with information regarding the domain you wish to add\n*Now that you’ve added a domain, take a look at the screenshot down below.\n** How to add a subdomain**\n1.click on the website and domains\n2.Add subdomain\n3.Fill the required filleds\n*On the left-hand menu click website and domains\n*After that, select the “Add sub domain” option that is seen in the following screenshot.\nFill the required filleds and then click ok *Now that you’ve added a sub domain, take a look at the screenshot down below.\n**The steps necessary to delete domains and subdomains**\n*Click the three dots that are located on the right side.*\n*Click remove website*\nKnow, How To find Apache version in Plesk\nThank You"},"title":"Domains/subdomains in Plesk"},"/docs/linux/an-introduction-to-the-linux-alternatives-command/":{"data":{"":" An introduction to the Linux alternatives command\nThis tutorial is to about the introduction of to the Linux alternatives command. Alternatives is a program that adds, deletes, updates, and displays data on the symbolic links that make up the alternatives system.\nBecause many users don’t care how their computer completes a job as long as it is successful, abstractions may be useful to users. In reality, as long as all of an application’s system calls are properly responded, it doesn’t always matter how anything is accomplished. Theoretically, a Linux system administrator may provide a wide range of system utilities based on their functions rather than the precise name of the executable, but doing so often requires a lot of symlinking and version management. Unless you use the alternatives command, that is.\nIt’s important to note that the alternatives command first existed as a substitute. This was originally an update-alternatives convenience tool from the Debian Linux project, written in Perl. The command was rewritten by Red Hat without the use of Perl, and it has since spread across Fedora-based distributions like Red Hat and CentOS as well as other distributions that rely on Red Hat to provide the functional definition of the Linux Standard Base (LSB).","check-alternatives#Check Alternatives":"Other advantages of the alternatives command include the ability to symlink dependent components when a certain option is selected. Alternatives keeps your discrepancies consolidated while while doing a lot of the hard work. To avoid having to always remember that emacs is really emacs-26.3 or that java is actually /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0, etc., you may check in on what alternatives are available:\nalternatives --list Now, you have a learned the introduction of Linux alternatives command. The alternatives command is an illustration of how both users and administrators can profit from some deft manipulation since Linux is all about choice and flexibility.\nMust Read: What are Runlevels in Linux and its understanding.","creating-a-new-alternative#Creating a new alternative":"It is simple to generate an alternative entry using the example situation of an old binary named em being replaced by the new variation nem. Although in most cases this isn’t required since the command isn’t precisely what people assume it is in the first place (java, for example, is seldom found under /usr/bin directly), you must rename the original command in this example. If you do need to rename a binary, the proper place to do so is in the binary’s RPM spec file so that the command to install the RPM supplies the binary with the new name.\nIn a pinch, particularly if you’re planning to phase the command out anyway, you could remove it from the system’s package management and just maintain a customised version of the old command accessible via /opt or something like.\nTake the original editor, which you have called em2, for this example (denoting its latest version number).\nNow, you may associate two binaries (em2 and nem) with the command em. Assume that em and nem are both little Emacs-style editors to help keep the terminology distinctions clear. In that instance, for the sake of simplicity, a very general word for the new alternative would be emacs (using the symbol to signify “micro”) or uemacs.\nOffer the following as a replacement for the original:\na location for the “generic” symlink a name for the alternative (I’ve decided upon uemacs, to make it clear that it’s a reference name rather than a specific binary) the binary to be executed when these symlinks are called a priority level to indicate which alternative is preferred alternatives --install /usr/bin/em uemacs /opt/em-legacy/em2 1 Since the new binary is your preferred binary, develop a high priority replacement:\nalternatives --install /usr/bin/em uemacs /usr/local/bin/nem 99 With the help of these commands, a new symbolic link, /usr/bin/em, is created that points to /etc/alternatives/em, which in turn can point to either /opt/em-legacy/em2 or /usr/local/bin/nem. The systems administrator chose the descriptive and memorable term uemacs as the human-friendly name for this collection of alternatives at random. Using the —config option, you can select the alternate symlink’s destination:\nalternatives --config uemacs There are 2 programs which provide 'uemacs'. Selection Command ----------------------------------------------- *+ 1 /usr/local/bin/nem 2 /opt/em-legacy/em2 ","removing-an-alternative#Removing an alternative":"Alternatives may assist users or administrators move to something new or they might be long-term solutions. Using the —remove-all option and the alternative’s “generic” name will eliminate all alternatives if you need to for whatever reason. Uemacs is used as an example here:\nalternatives --remove-all uemacs This deletes the symlink in /usr/bin and /etc/alternatives as well as everything else related to uemacs from the alternatives subsystem. Use the —remove option with the alternative name (in this case, uemacs) and the path of the choice you wish to drop if you only want to remove one option from an alternative:\nalternatives --remove uemacs /opt/em-legacy/em2 ","when-to-use-the-alternatives-command#When to use the alternatives command":"An easy-to-understand and practical example is the em command on your computer, which starts a simple text editor. It has long been the editor of choice for your user base; many individuals have built processes around it, and some people keep very specific configurations for it. Although em doesn’t support Unicode, your user base lately made it apparent to you that they can’t function without emoji functionality in their terminal editors.\nYou discover nem, a Unicode-capable branch of em, but you are aware that 99% of your customers are already used to em, have scripts that call em, and will never stop thinking of any alternative programme as em. The simple answer to this problem, as well as many others like it, is to provide the new nem binary as the preferred substitute for the em binary whenever the em command is used.\nAlthough manually constructing a symlink could seem alluring, it is neither centralised nor immune to changes from a package management.\nWhen handling “generic” application names, the alternatives command is most helpful. As “generic” isn’t usually generic in the UNIX world, just as “Kleenex” or “Xerox” isn’t always generic in the actual world, terminology like java, (x)emacs(-nox), (n)vi(m), whois, and iptables are often among of the first to have replacements specified for them. The alternatives command is not seen as a suitable option for really general names, such as EDITOR and CC. Because they are environment variables and need to be specified in /etc or $HOME/.profile, those phrases."},"title":"An introduction to the Linux alternatives command"},"/docs/linux/archiving-and-compressing-files-with-gnu-tar-and-gnu-zip/":{"data":{"":"","compressing-log-files#Compressing Log Files":"Some files are generated, especially log files that can increase to a large size, by long-term daemons, such as web or e-mail servers. While these files are not deleted, they can grow unmanageably large within a short period of time. Since they are plain texts, compression is effective; however, it makes no sense to use a tool such as tar. It makes sense to use gzip straight away in these cases:\n[root@Microhost ~]# gzip /var/log/mail.log The file is called mail.log.gz to replace the original /var/log/mail.log. To access this file’s contents:\n[root@Microhost ~]# gunzip /var/log/mail.log.gz However, you do not need to uncompress a file to access its contents in most cases. The tool gzip includes tools for accessing “gzipped” files with standard Unix tools. you can access file contents of gzip with following utilities zcat (Cat equivalent), zgrep (Grep equivalent) and zless (Lower Equivalent).\nThank You :)","extracting-files-from-a-tar-archive#Extracting Files from a tar Archive":"To extract files from a tar archive, issue the following command:\n[root@Microhost ~]# tar -xzvf latest.tar.gz The specified options have the following effects: -x extracts archive contents, -z filters the archive through the compression gzip tool, -v allows the verbose output to print a list of files as they’re extracted from the archive and -f specifies that tar will read input from the subsequently specified file latest.tar.gz","gzip-command#gzip Command":"A simple and standard method for compressing individual files is provided with gzip and the accompanying Gunzip command. As tar does not allow compression of the files which it archive, the gzip tools can only operate on single files. As tar does not. In the file test.txt the next command is added and comprised in test.txt.gz:\n[root@Microhost ~]# gzip test.txt This file can be decompressed using one of the following commands:\n[root@Microhost ~]# gunzip test.txt.gz [root@Microhost ~]# gzip -d test.txt.gz You can add the -v flag to improve the compression rate of verbosity and output statistics:\n[root@Microhost ~]# gzip -v test.txt gzip accepts standard input to compress the output of a text stream:\n[root@Microhost ~]# cat test.txt | gzip \u003e test.txt.gz The compression algorithm used by gzip in compressing files can be configured to use more compression and save time. A number argument between -1 and -9 controls this ratio. The default setup is -6. Also, gzip includes the helpful mnemonics –-fast (i. e. —1) and —best (i.e. -9):\n[root@Microhost ~]# gzip --best -v test.txt [root@Microhost ~]# gzip --fast -v test.txt [root@Microhost ~]# gzip -3 -v test.txt [root@Microhost ~]# gzip -8 -v test.txt ","tar-command#tar Command":"tar is a software tool for collecting multiple files into one file in other word we can say “archive”. However, gzip is a software application used for compression and decompression. We use file compression techniques for saving disk space. This report offers a summary of the use of tar and gzip :\nTAR’s intricacy is not based on its fundamental form, but on a number of options and settings that can be used to create archives and to interact with them.\nFor example: We have a tar file named latest-archive.tar . We will use below given command to extract the content of the tar file into present working directory.\n[root@Microhost ~]# tar -xf latest.tar Use the following command to create archive(wordpress.tar.gz) file of all files in the Wordpress directory:\n[root@Microhost ~]# tar -c wordpress \u003e wordpress.tar.gz By default, tar sends archive file contents to the standard output, which you can use to continue processing your created archive. You can opt for the -f option to bypass default output. The command following is the same as the previous command:\n[root@Microhost ~]# tar -cf wordpress.tar.gz wordpress "},"title":"Archiving and Compressing files with GNU Tar and GNU Zip"},"/docs/linux/change-ssh-default-port-22-to-custom-port/":{"data":{"":"\n1. Access your linux server using SSH with putty any third party software.\n2. Enter your sudo user password or root password.\n3. Open SSH configuration file using below command in your favorite editor.\n[root@ssh-port-change ~]# vi /etc/ssh/sshd_config 4. Add “Port 44” line in sshd_config file and save or exit the file.\n5. Restart ssh service using below command.\n[root@ssh-port-change ~]# systemctl restart sshd 6. Open port 44 or custom port in firewall(Firewalld,CFS,IPtables,Microhost cloud firewall,etc) which you have defined in ssh configuration file,if you are using any internal and external firewall on server. For Eg:- firewalld\n[root@ssh-port-change ~]# firewall-cmd --add-port=44/tcp --permanent [root@ssh-port-change ~]# firewall-cmd --reload Thank you.."},"title":"Change SSH Default Port 22 to Custom Port"},"/docs/linux/cheat-sheet-for-15-nmcli-commands-in-linux-rhel-centos/":{"data":{"":"\nDescription\nI will walk you through 15 different examples of using the nmcli tool in Linux. nmcli is a command-line programme that is open-source and may be used to control NetworkManager and report on the state of networks. It is utilised to a large extent by Linux specialists so that they can harness the power of Network Manager directly from the command line. Creating, displaying, editing, deleting, activating, and deactivating network connections, as well as controlling and displaying the status of network devices, are all possible tasks that may be accomplished with the help of nmcli.","10create-a-new-connection-profile#10.Create a new connection profile.":"If you want to create an Ethernet type connection profile using interface enp1s0, then you need to use the nmcli c add type ethernet connection command. command interface-name enp1s0.\nmcli c add type ethernet connection.interface-name enp1s0 ","11examine-the-networkmanager-polkit-permissions#11.Examine the NetworkManager Polkit Permissions ":"Use the nmcli general permissions command to check the Polkit permissions set up for different NetworkManager operations. A system administrator sets up these permissions or actions (in Polkit language), and users can’t change them.\nnmcli general permissions ","12using-the-nmcli-command-change-the-hostname#12.Using the nmcli command, change the hostname. ":"You can also change the system’s hostname with nmcli. You can use the nmcli general hostname command to find out what the current hostname is.\nnmcli general hostname ","13create-a-bridge-using-the-nmcli-command#13.create a bridge using the nmcli command":"Use the nmcli con add type bridge ifname bridge name\u003e command to make a bridge. In this example, we use the nmcli con add type bridge ifname br0 command to create a bridge called br0.\nnmcli con add type bridge ifname br0 ","14nmcli-command-to-disable-bridge-stp#14.nmcli command to disable bridge STP":"By default, the Spanning Tree Protocol (STP) will be turned on. To turn it off, use the nmcli con mod bridge-br0 bridge.stp no command.\nnmcli con modify bridge-br0 bridge.stp no If you want to turn on STP again, use the command nmcli con mod bridge-br0 bridge.stp yes.\nnmcli con modify bridge-br0 bridge.stp yes ","15convert-an-interface-to-an-unmanaged-interface#15.Convert an Interface to an unmanaged Interface":"Use the nmcli device status command to look at the list of interfaces and then the state of an interface.\nnmcli device status Conclusion\nnmcli is a command-line software that is open-source that may be used to report on the state of networks as well as control NetworkManager. Linux experts make extensive use of it so that they may access the power of Network Manager straight from the command line. This enables them to do their jobs more efficiently. With the assistance of nmcli, one is able to accomplish a wide variety of tasks, including creating, displaying, editing, deleting, activating, and deactivating network connections, as well as controlling and displaying the status of network devices. In addition, one is able to edit and delete network connection information.\nMust Read : How To Add a User and Grant Root Privileges on Ubuntu 18.04\nThankyou","1how-to-find-the-version-of-nmcli#1.How to find the version of nmcli":"You will need to run the nmcli —version command in order to determine the version of nmcli that is currently installed on your system.\nnmcli --version ","2how-to-double-check-each-and-every-connection-to-a-network-device#2,How to Double-Check Each and Every Connection to a Network Device":"The nmcli connection command is what you need to use to see all the network device connections that are available. If the nmcli connection command doesn’t have any parameters, it will show both system and user setting connections that have been set up.\nnmcli connection ","3checking-the-status-of-all-network-devices#3.Checking the Status of All Network Devices":"Use the nmcli device status command to verify the status of all network devices. This command displays both controlled and unmanaged devices.\nnmcli device status ","4how-to-display-the-status-of-a-radio-switch#4.How to Display the Status of a Radio Switch ":"If you wish to see the current status of the radio switches, use the nmcli radio all command.\nnmcli radio all ","5how-to-display-all-network-devices#5.How to Display All Network Devices":" nmcli device show ","6how-to-check-the-status-of-networkmanager#6.How to Check the Status of NetworkManager ":"Use the nmcli -t -f RUNNING general command to check the running status of NetworkManager in concise output mode.\nnmcli -t -f RUNNING general ","7network-manager-status-check#7.Network Manager Status Check":"nmcli -t -f is what you need to use to check the status of Network Manager as a whole in terse output mode. STATE general command\nnmcli -t -f STATE general ","8checking-terse-output#8.Checking Terse Output":"use the nmcli -t device command to show a list of all the network devices that are currently set up in a concise way.\nnmcli -t device ","9check-how-network-manager-logs#9.Check how Network Manager logs.":"Then you need to use the nmcli general logging command to check the current Network Manager logging settings.\nnmcli general logging ","uuid-what-is-it#UUID: what is it?":"A UUID, or universally unique identifier, is a 128-bit integer used to identify an object or entity on the Internet."},"title":"Cheat sheet for 15 nmcli commands in Linux (RHEL/CentOS)"},"/docs/other/add-user-and-give-limited-permission-to-the-host-in-zabbix/":{"data":{"":"\nDescription\nIn this article we will learn how to add user and give limited permission to the host in Zabbix..\nwhat is Zabbix used for :- Zabbix is open source software for monitoring networks, servers, virtual machines (VMs), and cloud services, among other IT parts. Zabbix lets you keep an eye on things like network usage, CPU load, and disc space usage.\nFollow the below steps to Add user and give limited permission to the host in Zabbix..","step-1---add-user#Step 1 - Add user":"After the first installation, Zabbix only knows about two users. The “Admin” user is a Zabbix “superuser,” which means that they have full access. User “guest” is a special default user. If a user doesn’t sign in, they’ll be able to use Zabbix as a “guest.” “guest” has no rights to Zabbix objects by default.\nTo add a new user, navigate to Administration \u003e Users \u003e Users in the dropdown menu \u003e select “Create User.”\nnavigate to Administration \u003e Users \u003e Users in the dropdown menu \u003e select \"Create User.\" Make sure to add your user to one of the existing groups, such as “Testing,” in the new user form.\nIn this pop-up, type the user’s email address. By default, a medium is always active, but you can set a time period for it to be active (see the Time period specification page for a description of the format). You can also change the severity levels where the medium will work, but for now, leave them all turned on. In the user properties, click Add, then click Save. The new user shows up in the list of users.","step-2---give-permission-for-limited-host#Step 2 - Give permission for limited host":"The following steps need to be taken in order to configure a host in the Zabbix frontend:\nNavigate to Configuration \u003e Hosts\nTo the right, click on “Create Host” (or on the host name to edit an existing host). In the form, enter the host’s parameters.\nThe clone and complete clone buttons on an existing host can also be used to make a new host. When you select “clone,” all host parameters and template links are kept (keeping all entities from those templates). Additionally, a full clone will keep things that are directly linked (applications, items, triggers, graphs, low-level discovery rules, and web scenarios).\nNote that the cloned version of a host will keep all template entities exactly the same as they were when they were first on the template. Any alterations that were made to those entities on the existing host level will not be cloned to the new host; instead, they will be the same as they were on the template. This includes updated item intervals, modified regular expressions, and prototypes added to the low-level discovery rule.\nNote: If you want to add this host to a particuler host group, then you need to select an already existing host group as seen in the screenshot below. You may check out this screenshot for more information if you want to do this.\nNavigate to Configuration \u003e Hosts \u003e create host And now you can access your host that was added to a specific host group by going to configuration \u003e host group. configuration \u003e host group After all, this is the last step to add limited host permission by user group, which means that users in that user group will only be able to access the hosts that you choose for them. follow the below steps.\nGo to Administrator \u003e user group \u003e select your user group \u003e select host permission To verify that everything you’ve done is right, sign out of Zabbix and log in with your user and password, and then show the user the permissions you’ve provided them. check the below screenshot.\nI really hope that you’ve got all of those steps down. to Add user and give limited permission to the host in Zabbix.\nMust Read :- https://utho.com/docs/tutorial/how-to-install-zabbix-agent-on-centos-7/"},"title":"User Permissions - Zabbix"},"/docs/platform/how-to-access-a-server-through-password-less-authentication/":{"data":{"":"","conclusion#Conclusion":"Hopefully, you have learned how to access a server through password-less authentication.\nThank You 🙂","introduction#Introduction":"In this article, you will learn how to access a server through password-less authentication.\nSSH, also known as Secure Shell or Secure Socket Shell, is a network protocol that gives users, particularly system administrators, a secure way to access a computer over an unsecured network. SSH also refers to the suite of utilities that implement the SSH protocol. Secure Shell provides strong password authentication and public key authentication, as well as encrypted data communications between two computers connecting over an open network, such as the internet.\nStep 1. Login server via putty.\nStep 2. Generate SSH key at your server.\n# ssh-keygen Step 3. Enter file in which to save the key (/root/.ssh/id_rsa): press enter\nStep 4. Enter passphrase (empty for no passphrase): press enter\nStep 5. Enter same passphrase again: press enter\nNow your SSH key will be created on .ssh folder with name id_rsa.pub\nStep 6. Use the following command to go to the.ssh directory.\n# cd .ssh Step 7. Use this command to display the content of a folder.\n# cat id_rsa.pub [caption id=“attachment_9778” align=“alignleft” width=“641”] SSH KEY Command Output[/caption]\nStep 8. You should now enter your login information for your Microhost account and head over to the SSH key area.\nStep 9. To import an SSH key, select it and click Import.\nStep 10. At this point, you need to paste the SSH key shown in step no.7 and specify the name.\nStep 11. With the SSH key we just imported into our microhost account, we can now set up a new server.\nStep 12. Login to your existing server and run the following command:\n# ll # cat id\\_rsa Step 13. Save this private key in the file “test.ppk” on your desktop. which is shown on the previous screenshot.\nStep 14. Now open the putty key generator and click on conversions. then select the import key.\nStep 15. Choose the test.ppk file, open it, and click “Save Private Key.” Then press OK.\nStep 16. Save the file on your desktop with the name test1.ppk\nStep 17. Open putty Click on “Auth” under the “SSH” option, browse to the “test1.ppk” file, then click “Open.”\nStep 18. Click on sessions. Write down your new server IP, which is deployed in step no. 11. then select open. Step 19. Write “root” in your terminal and press Enter to see access to your server without a password."},"title":"How to access a server through password-less authentication"},"/docs/platform/how-to-add-additional-storage-in-the-cloud/":{"data":{"":"\nLogin to Microhost Cloud Dashboard Select the cloud server in which you want to add additional storage and then click on “Actions” button. 3. When you click on “Manage cloud” option , A window will appear shown in the image below. You need to select “Storage” option and then fill the select size in GB and then click on “Add storage”.\n4. Additional storage will be added and you can check added additional storage by following process-\nIf you are using cloud server with windows operating system then you need to login in the server and click on the server manager -\u003e computer management -\u003e\nClick on Disk management.\nHowever, for Windows operating system . We will follow below steps for making additional disk online.\nTake the cursor on “ofline” and then right click on that.\nWhile clicking on that, output will be visible as below.\nWhile clicking on online the “disk” it would be online. However, we have to initialize the disk for creating the volume. Have a look on the below screenshot.\nAfter Initializing the disk, we have to format the disk first. Please see the below screenshot for reference.\nSelect the MBR option and then click on OK. Afterward , we can add a new volume drive by following steps. Click on “New Simple Volume” .\nWhile clicking on “New Simple Volume” a prompt will be shown like below.\nClick on Next as per the screenshot . In this section you can select the size of the partition. by default it will take complete space of drive.\nAfterward click on next to move further. In this section we can assign the name of new volume. Now click on next.\nIn this section we have format the disk with NTFS file system and then click on next.\nAfterward, we have to finish the process while clicking on finish.\nNow , A new drive will be visible in drive section of the system as per the given screenshot.\nIf you are using cloud server with linux operating system, then you need to follow these below mentioned steps.\nfdisk -l :– To list the all drives.\nfdisk /dev/vdb\nmount /dev/vdb1 /new/\nresize2fs /dev/vdb1\nmkfs.ext4 /dev/vdb1\nmount /dev/vdb1 /new/\nTHANK YOU :)"},"title":"How to add additional storage in the Microhost Cloud Server"},"/docs/platform/how-to-check-bandwidth-consumption-in-microhost-panel/":{"data":{"":" How to check Bandwidth consumption in Microhost panel\nStep 1. Login to Microhost Cloud Dashboard\nStep 2. Select the cloud server in which you want to add additional storage and then click on “Actions” button.\nManage a cloud\nStep 3. When you click on “Manage cloud” option , A window will appear shown in the image below. You need to select the “Analysis” option (By default its already on Analysis) . You can examine your CPU, Memory ,read/write ,traffic and Bandwidth utilization of the server with the help of graph .\nOverview of server\nStep 4. When you scroll down , the last graph is of “Daily Public Bandwidth usages ” of the current month . You can see your input/output bandwidth day wise by just moving the cursor as shown in the below screenshot.\nThank You!!"},"title":"How to check Bandwidth consumption in Microhost panel"},"/docs/platform/how-to-deploy-a-cloud-server-with-custom-iso/":{"data":{"":"","conclusion#Conclusion":"Hopefully, now you have learned how to deploy a cloud server with custom ISO.\nAlso read: How to take snapshot of a Microhost Cloud Server\nThankyou.","introduction#Introduction":"In this article, you will learn how to deploy a cloud server with custom ISO.\nWhy do we require custom ISO ?\nTo download and use the Custom/specific OS according to the client requirements .\nA Custom ISO file is an archive file that contains an identical copy (or image) of data found on an optical disc, like a CD or DVD. For any custom version of OS , you can download ISO file of that OS and Deploy the server with that file.\n1. At first, you need to login Microhost Cloud Dashboard\n2. Select the ISO section in Dashboard.\n3. You can download ISO file here . Choose the data center location , ISO file link and name of the server and click on Add ISO.\nNOTE : DOWNLOAD ISO FILE/LINK FROM THE OFFICIAL WEBSITE ONLY\nISO is downloaded and available .\n4. Now, create a new server and choose ISO section and that custom ISO file while deploying the cloud server .\nNOTE : DEPLOY THE SERVER ON THE SAME LOCATION AS ISO 5. Select cloud size ,options and enter host name of the server . 6. Click on deploy cloud server to deploy and mount the ISO .\n7. Server is in running status now :\n8. Now click on console and install the OS from the Cloud Console .\nConsole view : Here we are going to install centos 7 , You can install OS as per your requirement.\n9. After the full installation of OS, click on ISO section in the manage cloud and unmount the ISO by clicking on the unmount ISO\nServer deployed with Custom ISO ."},"title":"How to deploy a cloud server with custom ISO"},"/docs/platform/how-to-destroy-microhost-cloud-server/":{"data":{"":"","click-on-the-cloud-servers-option-present-on-the-top-left-#Click on the Cloud Servers option present on the Top left .":"","copy-and-paste-the-required-string-as-shown-below-and-click-on-the-destroy-server-button#Copy and paste the required string as shown below and click on the Destroy Server button.":"NOTE : Please make sure that you have data/backup of the server before destroying your server as it could not be restored again .\nServer has been deleted.\nThankyou.","select-the-server-you-want-to-deletedestroy-by-clicking-on-the-manage--destroy-cloud-options-#Select the server you want to delete/destroy by clicking on the Manage \u0026lt; Destroy Cloud options .":"\nAt first, you need to login Microhost Cloud Dashboard Select the cloud server that you want to delete. Click on “actions” button, Afterward click on “Destroy Cloud” option as shown in screenshot given below. Click on the Cloud Servers option present on the Top left . Select the server you want to delete/destroy by clicking on the Manage \u003c Destroy Cloud options . "},"title":"How to destroy MicroHost cloud server"},"/docs/platform/how-to-enable-weekly-backup-in-microhost-cloud-server/":{"data":{"":"\nWeekly backup is a system level backup in which an image copy of complete server is created. You can not retrieve a single file from the weekly backup. To retrieve a single file from backup you need to create a new server and then retrieve the file from server.\n1. At first, you need to login Microhost Cloud Dashboard\n2. Select the cloud server for which you want to enable backup.\n3. When you click on “Manage cloud” option , A window will appear shown in the image below. You need to select “Backup” option and then click on “Enable Backup”.\n4. Backup will be created.\nThankyou"},"title":"How to enable weekly backup in Microhost Cloud server"},"/docs/platform/how-to-install-wine-on-rhel-8/":{"data":{"":" How to install Wine on RHEL 8","description#Description":"In this article we will learn how to install wine on RHEL 8.Starting with the very first step. Wine is a compatibility layer that was developed for multiple POSIX-based operating systems, such as Linux, Macintosh, and BSD, to enable these systems to run Windows-based software. Wine is available for free and is open source. Wine is a programme that, in its most basic form, automatically translates Windows API calls into POSIX calls. This eliminates the speed and memory penalties that are associated with using other methods and enables you to integrate Windows applications onto your desktop in an uncluttered manner. It is simple to understand and not too difficult to put into practise. Also, the installation process is relatively straightforward in virtually all of the well-known Linux variants.","step-1-update-server#Step 1: Update Server":" yum update ","step-2-install-epel-release-repository#Step 2: Install EPEL Release Repository":"You will only be able to obtain the wine package through the EPEL repository. In order to install and activate this repository, you will need to use the yum install epel-release command, as demonstrated further below.\nyum install epel-release ","step-3-install-wine-package#Step 3: Install Wine package":"With the yum install wine command, which will be demonstrated further down, you will be able to install the wine package from the EPEL repository. The package, as well as all of its dependencies, will be downloaded and installed as a result of this action.\nyum install wine ","step-4-verify-installation-of-package#Step 4: Verify Installation of package":"After the installation has been completed successfully, you will be able to validate all of the wine-related packages that have been installed by querying the rpm database using the rpm -qa | grep -i wine command, as will be demonstrated below.\nrpm -qa | grep -i wine ","step-5-check-version-of-package#Step 5: Check Version of package":"Using the wine —version command, as seen below, is another option for determining the currently installed version of wine.\nwine --version I really hope that you’ve got all of those steps down for how to install wine on RHEL 8"},"title":"Wine on RHEL 8"},"/docs/platform/how-to-rebuild-microhost-cloud-server/":{"data":{"":"\nRebuilding a server means creating a server with clean OS installation and it will erase all current data from server. It is just like formating a server with same configuration.\nPlease Use this feature only if you want to start your cloud server all with clean OS installation. We are sharing with you the steps to rebuild a cloud server -\nLogin to Microhost Cloud Dashboard Click on cloud server and select the server that you want to rebuild. Click on Manage cloud -\u003e Rebuild Select the OS in which you want to rebuild Fill the text that “ I want delete my data from current server and build fresh server\" Click on “Rebuild cloud server”. After rebuild server login details will be sent on registered email id.\nThankyou."},"title":"How to rebuild Microhost Cloud Server"},"/docs/platform/how-to-resize-upgrade-downgrade-cloud-server/":{"data":{"":" Resize Microhost Cloud instance\n1. First, You need to login Microhost Cloud Dashboard.\n2. Select the cloud server that you want to upgrade.\n3. When you click on “Manage” option , A window will appear shown in the image below. You need to select “Resize”\n4. After getting above image you need to select the desired configuration, Suppose your requirement is 4vCPUs and 8GB RAM, then scroll down and select Resize cloud server.\n5. After Resize, your server will upgraded.\n6. After upgrade the cloud server, you can Downgrade also. First you need to select the configuration and scroll down and click on Resize Cloud server.\n7. After the resize cloud server, your server will be downgraded to your selected plan.\nThank you!!"},"title":"How to resize (upgrade/downgrade) cloud server."},"/docs/platform/how-to-take-snapshot-of-a-microhost-server/":{"data":{"":"","conclusion#Conclusion":"Hopefully, you have learned take snapshot of a Microhost Cloud Server.\nAlso read: How to deploy a cloud server with custom ISO\nThankyou.","in-this-article-you-will-learn-how-to-take-snapshot-of-a-microhost-cloud-server#\u003cstrong\u003eIn this article, you will learn how to take snapshot of a Microhost Cloud Server.\u003c/strong\u003e":"\nIntroduction In this article, you will learn how to take snapshot of a Microhost Cloud Server. Snapshot is a feature in microhost cloud platform that is an instant “picture” of the file system of your server at a certain time period or we can say Cloning of a server of a particular time frame. Snapshot images use minimal storage space.\n1. At first, You need to login to Microhost Cloud Dashboard - 2. Select your server of which you want to take snapshot and click on manage cloud.\n3. When you click on “Manage cloud” option , A window will appear shown in the image below. You need to select “snapshot” option and then click on “Take live snapshot”.\n4. A pop-up will appear asking for extra charges for snapshot.\nClick OK and snapshot will be created.\n5. You can check created snapshots by this option-","introduction#Introduction":""},"title":"How to take snapshot of a Cloud Server"},"/docs/plesk/add-txt-record-in-plesk/":{"data":{"":"","conclusion#conclusion":"Hopefully, now you have learned how to add TXT record in Plesk.\nAlso read: How to add MX record in Plesk.\nThank You 🙂","introduction#Introduction":"In this article, you will learn how to add TXT record in Plesk.\nA TXT record, which is an abbreviation for “text record,” is a specific kind of resource record that is used by the Domain Name System (DNS) to provide the ability to associate random text with a host or other name. This text can include information that is readable by humans about a server, network, data centre, or other accounting information. TXT records are modified as “TXT records.”\nStep 1. Log into your Plesk with your server password by searching server_ip:8880 in your browser.\nStep 2. Go to Hosting and DNS under the menu of websites and domains, then click on DNS settings.\nStep 3. Click on “Add Record.”\nStep 4. In the record type drop-down menu, select TXT record.\nIn the domain field here, we are not using any subdomains, so for the main domain, which is micro.com, we are keeping this field empty.\nIn the TTL field, you can assign any value in seconds; we have entered 3600. in the TXT record field, entered the TXT record. then select OK. NOTE: Use your main domain instead of micro.com."},"title":"How to add TXT record in Plesk"},"/docs/plesk/analysis-of-postgresql-and-mysql-a-comparative-study/":{"data":{"":"","few-reasons-why-more-and-more-businesses-are-choosing-postgresql-as-their-go-to-database#\u003cstrong\u003eFew reasons why more and more businesses are choosing PostgreSQL as their go-to database\u003c/strong\u003e.":"","how-can-utho-support-your-postgresql-and-mysql-requirements#\u003cstrong\u003eHow can Utho support your PostgreSQL and MySQL requirements?\u003c/strong\u003e":"PostgreSQL and MySQL are among the most highly regarded open-source relational databases in the modern software landscape. PostgreSQL is highly advantageous for enterprise-level applications that involve frequent write operations and intricate queries. Its robust features make it a top choice for handling large and complex databases. On the other hand, MySQL is more suitable for beginners due to its easier learning curve. It allows for quicker development of new database projects from scratch. Few reasons why more and more businesses are choosing PostgreSQL as their go-to database. PostgreSQL simplifies the process of setting up and utilizing databases, whether on-premises or in the cloud. In environments with a significant number of databases, both private and public, automating the creation of PostgreSQL instances can significantly save time.\nPostgreSQL is reliable: PostgreSQL implements a Write-Ahead Log mechanism to safeguard against system crashes. This ensures that any committed transactions, that have not yet been written to the database, can be recovered by replaying the Write-Ahead Log. As a result, these transactions are successfully committed without loss of data.\nPostgreSQL is extensible : PostgreSQL is like a customizable toolbox. Its extensibility means you can easily add new tools or features to tailor it to your specific needs. You can create custom data types, operators, and functions, and even plug in entire extensions, making it flexible and adaptable for different uses.\nPostgreSQL is fast: PostgreSQL is a performance-enhancing feature that includes enhanced partition handling, increased efficiency in parallel processing, faster indexing speeds, and the elimination of concurrency barriers. PostgreSQL is secure: PostgreSQL is widely recognized for its strong focus on data integrity and robust security features, including row-level security and advanced authentication mechanisms. This reputation positions it as a highly secure database system.\nWhat is MySQL and what is it used for? MySQL is a highly efficient, dependable, and easily expandable open-source relational database system. It is specially developed to manage demanding, critical production applications with heavy data loads. As it is managed by a robust RDMS, MySQL is a widely used and user-friendly database that requires minimal resources in terms of memory, disk space, and CPU usage.\nMySQL is widely compatible: Despite its frequent association with internet applications and web services, MySQL was purposefully designed to have broad compatibility with a range of technologies and architectures. It is supported on all major computing platforms, including Unix-based systems like various Linux distributions and Mac OS, as well as Windows.\nMySQL databases are relational: Databases such as MySQL store data in various tables that are highly structured and separated, rather than relying on a single comprehensive repository or collections of unstructured documents. This design enables RDBMSs to efficiently optimize processes such as data retrieval, information updates, and more advanced actions such as aggregations.\nMySQL is open-source: These options offer organizations a higher degree of flexibility when considering utilizing MySQL. The open-source nature of the releases, which are publicly and community-driven, enhances MySQL’s documentation and online support culture, while also guaranteeing that any new or ongoing developments remain in line with current user demands.\nWhich is better MySQL or PostgreSQL?\nAlthough MySQL and PostgreSQL possess several similarities, the variances between them are substantial and may cause confusion for both novice and expert database managers. It is evident that MySQL has effectively enhanced itself to remain pertinent, while PostgreSQL stands out for its lack of licensing requirements and additional features such as table inheritance, rules systems, custom data types, and database events. As a result, PostgreSQL takes the lead over MySQL in this regard.\nHow can Utho support your PostgreSQL and MySQL requirements? ","utho-provides-a-range-of-services-to-fulfill-your-mysql-and-postgresql-needs#Utho provides a range of services to fulfill your MySQL and PostgreSQL needs.":"Utho Relational Database Service is a comprehensive suite of managed services designed to streamline the process of setting up, managing, and expanding relational databases in the cloud. Through our flagship offering, Utho RDS for MySQL, users can quickly deploy scalable MySQL servers with minimal effort and cost-effective options for resizing hardware capacity.\nSimilarly, Utho Relational Database Service for PostgreSQL makes it easy to set up, operate, and scale PostgreSQL deployments in the cloud. Furthermore, it efficiently handles intricate and labor-intensive administrative responsibilities, including upgrading PostgreSQL software, managing storage, and performing backups to ensure disaster recovery.\nGet started with MySQL and PostgreSQL on Utho by creating a free account today.","what-is-mysql-and-what-is-it-used-for#\u003cstrong\u003eWhat is MySQL and what is it used for?\u003c/strong\u003e":""},"title":"Analysis of PostgreSQL and MySQL: A Comparative Study"},"/docs/plesk/apache-virtual-hosts-setup-on-centos-7/":{"data":{"":"","create-new-virtual-host-files#Create New Virtual Host Files":"This is the virtual host file to specify how the Apache web server is to answer the various domain requests and how our separate websites are configured.\nIn order for us to start by setting the directory in which our virtual hosts are saved, and the directory in which Apache is told that the virtual host is ready to serve visitors. All of our virtual host files are maintained by the sites-available directory, while the sites-enabled directory has symbolic links to virtual hosts that we want to publish. By typing, we can create both directories:\n[root@Microhost]# mkdir /etc/httpd/sites-available [root@Microhost]# mkdir /etc/httpd/sites-enabled [ht_message mstyle=“alert” title=“NOTE” \" show_icon=“true” id=\"\" class=““style=”” ]The Debian contributor introduced this directory layout but we include it here to make it even more flexible with our virtual hosts management (as this is easier to allow and uncheck virtual hosts temporarily)..[/ht_message]\nIn sites-enabled directory, we should tell Apache to search for virtual hosts. In order to achieve this, we will edit the main Apache configuration file and add an optional line for further configuration of files. We can edit the file by following command.\n[root@Microhost]# /etc/httpd/conf/httpd.conf Add the following line at the end of the file content.\nIncludeOptional sites-enabled/*.conf save the file and exit from the text editor.","create-the-first-virtual-host-file#Create the First Virtual Host File":"Create a configuration file for domain1.com at the below location.\n[root@Microhost]# vi /etc/httpd/sites-available/domain1.com.conf The configuration file should look like :\n\u003cVirtualHost *:80\u003e ServerName domain1.com ServerAlias www.domain1.com DocumentRoot /var/www/domain1.com/public_html ErrorLog /var/www/domain1.com/error.log CustomLog /var/www/domain1.com/requests.log combined \u003c/VirtualHost\u003e save the file and exit from the text editor.\nNow do the same process for another domain.\n[root@Microhost]# vi /etc/httpd/sites-available/domain2.com.conf The configuration file should look like\n\u003cVirtualHost *:80\u003e ServerName domain2.com ServerAlias www.domain2.com DocumentRoot /var/www/domain2.com/public_html ErrorLog /var/www/domain2.com/error.log CustomLog /var/www/domain2.com/requests.log combined \u003c/VirtualHost\u003e save the file and exit from the text editor.","creation-of-test-pages-for-each-domains#Creation of test pages for each domains":"Let us now create some content to serve, as we now have a directory structure in place.\nOur pages are very simple because this is only for demonstration and testing. For each site that identifies the given domain, we will only make an index.php page.\nStart with domain1.com. Let’s start. In our editor, we can open an index.php file by typing:\n[root@Microhost]# vi /var/www/domain1.com/public_html/index.php copy the below content and paste it into the file.\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003cbody\u003e \u003ch1\u003eMy first PHP page\u003c/h1\u003e \u003c?php echo \"Hello World!\"; ?\u003e \u003c/body\u003e \u003c/html\u003e Save the file using :wq and exit from the text editor.\nWe can perform the above steps for domain2 also, only we have to create a file on domain2.com location as given below:\n[root@Microhost]# vi /var/www/domain2.com/public_html/index.php copy the below content and paste it into the file.\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003cbody\u003e \u003ch1\u003eMy Second PHP page\u003c/h1\u003e \u003c?php echo \"Hello World!\"; ?\u003e \u003c/body\u003e \u003c/html\u003e Save the file and exit from the text editor.","creation-of-virtual-host-directory#Creation of virtual host directory":"Our document root is set to individual directories in the /var/www directory and is the top level directory that Apache looks to find the content to serve. For each of the virtual host we plan to make, we will create a directory here.\nWe will create a public html directory that contains our current files in each of these directories.\nThese directories can be made by the mkdir command (using the -p flag to create a folder with a nested folder inside it):\n[root@Microhost]# mkdir -p /var/www/domain1.com/public_html [root@Microhost]# mkdir -p /var/www/domain2.com/public_html We should also change some of our permissions to ensure that the general web directory and all the files and folders inside are allowed access to pages so that they can be served correctly:\n[root@Microhost]# chmod -R 755 /var/www You should now have the permissions on your web server to serve content and the content of the corresponding folders should be created by your user.","enable-the-new-virtual-host-files#Enable the New Virtual Host Files":"We must now enable our virtual host files so that Apache knows how to serve visitors. In this way, in the sites-enabled directory, we can create a symbolic link for each virtual host:\n[root@Microhost]# ln -s /etc/httpd/sites-available/domain1.com.conf /etc/httpd/sites-enabled/domain1.com.conf [root@Microhost]# ln -s /etc/httpd/sites-available/domain2.com.conf /etc/httpd/sites-enabled/domain2.com.conf Now restart the apache services.\n[root@Microhost]# systemctl restart httpd Thank You :)","installation-of-apache#Installation of Apache":" [root@Microhost]# yum -y install httpd Now the Apache server has been installed. We will enable the apache service so that it will automatically up in boot time.\n[root@Microhost]# systemctl enable httpd.service Now we will start the service of apache server by following command:\n[root@Microhost]# systemctl start httpd.service [ht_message mstyle=“alert” title=“NOTE” \" show_icon=“true” id=\"\" class=““style=”” ]The setup example in this guide makes one virtual host for domain1.com and another for domain2.com . These are mentioned in the entire guide, but you should replace your own domains or values as you follow. .[/ht_message]","introduction#Introduction":"The web server of Apache is the most popular way to deliver web content. It serves over half of all active websites in the Internet and is extremely powerful and flexible.\nApache divides its features and components into separate units, which can be independently customized and set up. A virtual Host is called the basic unit describing a single site or domain. Virtual hosts allow one server, through a matching system, to host several domains or interfaces. This is important for those who want to host more than one VPS site.\nEach configured domain will direct the visitor to a certain directory that contains information on this website without indicating that the same server is also responsible for other websites. This scheme can be expanded without software limits provided the traffic of all the sites is handled by your server.","prerequisites#Prerequisites":" Log in to the server with the ssh. The account should have the root privilege. Update the server packages using yum update -y "},"title":"Apache Virtual Hosts setup on CentOS 7"},"/docs/plesk/bash-vs-cmd-decoding-the-battle-of-command-line-titans/":{"data":{"":"","how-does-bash-function#\u003cstrong\u003eHow does Bash function?\u003c/strong\u003e":"","what-are-the-advantages-of-using-bash#**What are the advantages of using Bash?":"","what-are-the-advantages-of-utilizing-a-command-prompt#\u003cstrong\u003eWhat are the advantages of utilizing a Command Prompt?\u003c/strong\u003e":"Bash and CMD are important tools in the world of computing. Bash, found in Unix-like systems, helps users efficiently navigate and control their systems using text-based commands. CMD, associated with Windows, offers a similar approach, providing a toolkit for executing commands. Both are crucial for system management, used by administrators, developers, and enthusiasts. Join us as we explore the unique features of Bash and CMD in this brief overview and discover which one is the better command-line interface.\nWhat is Bash? Bash serves as a UNIX shell and a command-line interpreter, simultaneously playing the roles of both. Recognized as a commonly utilized programming language, Bash supports a range of functions, variables, loops, and conditional statements, resembling features found in several other programming languages. Users can leverage Bash to interpret commands and execute multiple actions.\nHow does Bash function? From a technical standpoint, Bash serves as a command interpreter, processing and executing basic system commands like ls or mkdir. This interaction is the primary way of working with Bash. Additionally, there’s a second method involving batch files, containing Bash code. Mastering Bash scripting, which involves writing and executing batch files, provides a significant advantage, allowing automation of tasks and the creation of complex system commands.\n**What are the features of Bash? **\n**Here are fundamental concepts in Bash that every user should acquaint themselves with:\nCommands:** A command serves as an instruction directing the shell’s actions, and it can range from simple to complex, entered into the terminal through typing.\nArguments: Arguments consist of supplementary information provided to a command to alter its behavior, encompassing options, filenames, or other types of data.\nVariables: Variables serve as storage for data utilized by the shell or scripts, capable of being assigned values and employed within commands or scripts.\nFunctions: Functions are employed to group commands together, enabling the execution of specific tasks. They can be invoked either from the command line or within a Bash script.\nRedirection: Redirection is the process of directing a command’s output to a file or another command. This functionality enables users to save the output to a file or utilize it as input for another command in the command prompt.\nWildcards: Wildcards serve the purpose of matching patterns in filenames or other data, allowing the selection of multiple files or the execution of operations on groups of files.\n**What are the advantages of using Bash? **\nThe introduction of windows and menus was a significant advancement in computer software development, so why revert to using CLIs like Bash? CLI usage persists due to several distinct advantages over GUIs. Let’s delve into some of these advantages.\nEnhance your operating system access efficiency: Individuals opt for Bash when they seek to manage their computer or OS without navigating through GUI menus, options, and windows. Additionally, using Bash instead of a GUI is more resource-efficient, as it eliminates the need for the computer to allocate resources to render graphical output. This makes Bash an appealing choice when running multiple programs, a virtual machine, or working with limited computing resources.\n**\nInput and output with text files:** Bash simplifies the creation and editing of text files, including CSVs. Given that text files are among the most prevalent means of storing and processing data, Bash proves to be excellent for tasks such as organizing and refining data, sorting and filtering data, scrubbing and refreshing data.\nAutomate with ease: Bash facilitates the automation of tasks on your computer, particularly beneficial when your job entails repetitive functions.\nWhat are the primary use cases of Bash? Key Applications of Bash:\nScripting: Bash scripting empowers users to create scripts, sequences of commands, enabling the automation of repetitive tasks, system administration, and the development of intricate workflows.\n**\nFile and Directory Management:** Bash simplifies file and directory operations, encompassing tasks such as creating, deleting, copying, moving, and renaming files and directories.\nRemote Server Management: Bash is commonly employed to establish secure connections to remote servers through SSH (Secure Shell) and execute operations on distant systems.\nSoftware Development: Bash scripts find application in software development workflows, handling tasks such as build automation, deployment, and testing.\nWhat are the primary use cases of CMD? System Information: CMD provides commands like systeminfo to retrieve detailed information about the system, including hardware and software configurations.\nNetwork Troubleshooting: Commands like ipconfig, ping, and tracert help diagnose and troubleshoot network-related issues.\nTask Management: CMD provides commands like tasklist and taskkill to view and manage running processes and applications.\nRemote Access: CMD supports remote access and management of other systems using commands like psexec and ssh.\nWhat is CMD (Command Prompt)? CMD (Command Prompt) serves as a command-line interpreter on Windows operating systems, offering a text-based interface for executing diverse system and application commands, as well as facilitating scripting and automation tasks. It is commonly known as the “Windows command prompt” or simply the “command prompt.”\nWhat is the functioning mechanism of Command Prompt? The command-line interface (CLI) accepts text commands entered through a keyboard. Although CLIs may have varying syntaxes, they generally carry out similar operations. Upon command execution, the computer interprets and performs the specified actions, while the CLI offers user feedback, including error messages or output from the executed commands.\nWhat are the advantages of utilizing a Command Prompt? Using a command-line interface (CLI) offers numerous advantages, with the most notable being:\nSpeed: The CLI allows for swift execution of commands, enabling the combination of multiple commands into a single line of text for program execution. This efficiency surpasses the navigation through menus in a GUI.\nResources: The CLI demands fewer computing resources for executing commands compared to a graphical interface.\nRepetitive Tasks: The CLI proves effective in automating repetitive tasks, allowing the creation of batch files to automate tasks at any specified time.\nPower-user: A CLI is well-suited for power users as it grants access to commands not available in a GUI. For instance, certain system-protected tasks cannot be accessed through a GUI.","what-are-the-features-of-bash#**What are the features of Bash?":"","what-are-the-primary-use-cases-of-bash#\u003cstrong\u003eWhat are the primary use cases of Bash?\u003c/strong\u003e":"","what-are-the-primary-use-cases-of-cmd#\u003cstrong\u003eWhat are the primary use cases of CMD?\u003c/strong\u003e":"","what-is-bash#\u003cstrong\u003eWhat is Bash?\u003c/strong\u003e":"","what-is-cmd-command-prompt#\u003cstrong\u003eWhat is CMD (Command Prompt)?\u003c/strong\u003e":"","what-is-the-functioning-mechanism-of-command-prompt#\u003cstrong\u003eWhat is the functioning mechanism of Command Prompt?\u003c/strong\u003e":""},"title":"Bash vs. CMD: Decoding the Battle of Command Line Titans"},"/docs/plesk/basics-information-of-apache-configuration/":{"data":{"":"\nThe Apache HTTP web server is the de facto standard for general HTTP services in many respects. Thanks to its large number of modules, it offers versatile support for proxy servers, URL rewriting, and granular access control. In addition, web developers also prefer Apache to support server-side scripting using CGI, FastCGI, and embedded interpreters. Such features make it easier to execute complex code quickly and efficiently. Although there are many popular alternatives to Apache, also within the bounds of open source, the scope of Apache use is remarkable.\nApache does not without any expense the exceptional degree of flexibility; this takes on the form of a configuration system that is often confusing and sometimes complicated. We have therefore developed this document and a number of other guides to tackle this issue and explore some more advanced and optional Apache HTTP Sever features.\nIf you would like to have a working web server and install Apache for the first time, we suggest using the corresponding “Apache development guide” for your Linux distribution. Try trying a suitable LAMP guide for your delivery, if you need a more full LAMP stack. This guide assumes that you have an up to date Linux setup, installed Apache successfully, and logged into a root access shell session.","apache-basics#Apache Basics":"The default Apache settings vary widely between different Linux distributions. All distributions from Debian, Ubuntu, and Gentoo refer to Apache as “Apache2” and bring configuration files into the directory /etc/apache2/. Certain distributions such as Fedora, CentOS and Arch Linux refer to Apache as “httpd,” and store /etc/httpd/ configuration files. While we allow you to learn about the default configuration of your Apache server, most configurational choices do not differ between the operating systems. The main obstacles to Apache’s setup are to grasp the regular configurations of the implementations and their variations from the upstream Apache.\nYou may use the “init” scripts to manage basic Apache features to safely and quickly start, stop or restart the server. The init script can also reload the configuration and check the server status. Edit the correct command to access these functions:\n/etc/init.d/apache2 start /etc/init.d/apache2 stop /etc/init.d/apache2 restart /etc/init.d/apache2 reload /etc/init.d/apache2 status If you use a distribution referred to as httpd by Apache, the commands are as follows:\n/etc/init.d/httpd start /etc/init.d/httpd stop /etc/init.d/httpd restart /etc/init.d/httpd reload /etc/init.d/httpd status The path to the script may be /etc/rc.d/init.d/ for some versions instead of /etc/init.d/.\nIn the init script with the command mod_disk_cache on Debian-based distributions contain the functions to monitor the htcache functionality:\n/etc/init.d/apache2 start-htcacheclean /etc/init.d/apache2 stop-htcacheclean Further functions from the command line interface are also supported. You can use the following command in Debian and Ubuntu systems to test the syntax of your Apache configuration files without restarting the server and trying it:\napache2ctl -t In CentOS and Fedora systems, use the following form:\nhttpd -t Furthermore, the apache2ctl -S or httpd -S Commands provide an update on virtual machines that currently run, which include the port the host listens on, the virtual host’s name (i.e. the domain) and site configuration information including file names and line numbers.\nThe “master” file for Apache is usually located in the httpd.conf. This file is in the apache2.conf file in Debian distributions, with a user-specific configuration in the httpd.conf file, including the master file, the master file contains some other files. To receive a list of the following items, submit an order according to your distribution:\ngrep \"Include\" /etc/apache2/apache2.conf grep \"Include\" /etc/apache2/httpd.conf grep \"Include\" /etc/httpd/httpd.conf Note that the order of these files can affect the web server behavior. When later options contradict options set in previous files, then earlier options are overridden. Knowing the current default configuration can be a valuable learning experience.","configuration-file-organization#Configuration File Organization":"One of the most common use cases for the Apache web server is to use its “virtual hosting” capabilities, which allow a single instance of Apache to serve numerous websites and subdomains. Because most websites don’t tend to use a significant amount of system resources, virtual hosting is often a great way to fully utilize a web server. As a result of this capability, configuration files for virtual hosts can be complex and difficult to organize. There are two major approaches to the solution for this problem.","create-a-single-virtual-hosts-file#Create a Single Virtual Hosts file":"For each virtual host, the Debian method of maintaining a single configuration file can be useful in managing many noninterlinked sites or for the editing of various distinct and unprivileged users. However, there are circumstances in which too many virtual host files may cause confusion and increase the maintenance burden by setting the same configuration group for a collection of hosts.\nFor these instances, the easiest way to keep Apache installed would be to provide a single file. This is the chosen host organization in some distributions, such as CentOS, Fedora, and Arch Linux. When checking Apache’s default distribution configuration, there’s normally a conf.d/directory where you can store user-created configuration. When you want to merge multiple virtual host configuration files into one file, create a vhosts.conf in the conf.d/ folder and add the entire configuration options in that file. Theconf.d/folder is located within the /etc/ directory of Apache, either: /etc/apache2/conf.d/or, where your distribution is concerned, /etc/httpd/conf.d/ .\nBoth settings are essentially similar, but can be implemented conveniently in different scenarios. The structure of the configuration file you choose depends on the specifications of your particular application.","symbolic-links-and-the-debian-way#Symbolic Links and the Debian Way":"To order to enhance usability, the Debian project enables users to effectively prevent changing the web server’s “foundation configuration.” As a result, Debian and Ubuntu use symbolic links to allow and disable various configuration options for administrators without fully erasing configuration options.\nMake sure that your apache.conf or httpd.conf file has the correct line if you are using an operating system other than Debian or choose to use the sites-enabled organization to customize your settings.\nInclude /etc/httpd/sites-enabled/ Include /etc/apache2/sites-enabled/ You need to use a command like: mkdir -p /etc/httpd/sites-enabled/. if you haven’t created this directory yet. Now the setup options for any files that you store in those directories will be included on your Apache server. Please use the following command to create a connection to this directory:\nln -s /etc/httpd/vhosts/abc.com /etc/httpd/sites-enabled/abc.com The syntax for creating symbolic links is ln -s followed by the original or “goal” file and the path to the link to be connected. If you skip the final word, ln will build a connection in the current directory with the same name as the target file. The original file will not be affected if you delete a connection. Apache can follow multiple layers of symbolic connections, but this can be confusing for itself.\nOne advantage of this is that a virtual host can keep its configuration files close to the other associated host files. All your virtual host-related services are mostly located in a /srv/www/abc.com/ directory. Under the DocumentRoot, directory, logs directory and application support directories, public_html/,logs/and application/ are stored. This organization helps you to find it convent to store your configuration file with your virtual host in /srv/www/abc.com/. This makes it easy to back up and transfer a virtual host, since all files are in one directory. The symbolic connection can be generated as following if the virtual host set up file is located at /srv/www/abc.com/apache.conf you might create the symbolic link as follows:\nln -s /srv/www/abc.com/apache.conf /etc/apache2/sites-available/abc.com You can use the a2ensite and a2dissite software to handle virtual host files if you are using a Debian distribution. You can also use/etc/apache2/sites-enabled/abc.com to manually connect your configuration files. When you do not use a Debian distribution, the symbolic relation may look the same, but file names and locations can change somewhat:\nln -s /srv/www/abc.com/apache.conf /etc/httpd/conf.d/abc.conf "},"title":"Basics Information of Apache Configuration"},"/docs/web-servers/nginx-enable-tls-or-https-connections/":{"data":{"":"\nThe Secure Socket Layer (SSL) is the successor to Transportation Layer Security (TLS). It provides stronger and more powerful HTPS and includes non-SSL improvements such as Forward Confidentiality, modern OpenSSL cipher suites, and HSTS-compatibility.\nA single NGINX installation may host a number of websites and any number that use the same TLS certificate and key. This guide describes different scenarios for adding a TLS certificate to the NGINX setup of your domain.","before-you-begin#Before You Begin":" You need root user accesssudo privileged user account. A TLS certificate and key are required for your site. If you are a private or internal location, or are simply experimenting, the certificate can be signed by yourself. If this is what your website wants, you can can use a commercial certificate chain. See our instructions to build a self-signed certificate or a signing certificate submission, if you don’t already have a certificate and server key. Make sure the NGINX has been compiled with - http ssl module if you have compiled from source code. Check for nginx -V efficiency. ","configure-a-single-https-site#Configure a Single HTTPS Site":"Scenarios: You have a domain certificate, and you would like NGINX to run over HTTPS on a single website. Scenario:\nJust use the setup of the http block in the previous section with only one site to deal with. You should not include ssl * instructions in the website configuration file in this case. Nonetheless, you will tell NGINX that port 443 for HTTPS connections should be listening instead of port 80. For further information, see the SSL module for NGINX docs.\n1. For example, below is a simple site configuration that works with the above-mentioned http block. This server block provides your site with IPv4 and IPv6 support, but you have no HTTP support only over HTTPS. In order to access your website, you need to type https:/ in the browser.\nIt is just a first step; without HSTS or by redirecting HTTP requests to port 443 you probably would not like to use this configuration.\nserver { listen ssl default_server; listen [::]:ssl default_server ; server_name abc.com www.abc.com; root /var/www/abc.com; } 2. After changes to the NGINX config files, reload your setup:\nnginx -s reload 3. Go to the web browser of your site or IP of cloud server to ensure that https:// is defined in the URL. Your HTTPS website will load. The browser warns you of an insecure link if you have a self-signed certificate. Activate and link the advertising.","configure-multiple-sites-with-a-single-certificate#Configure Multiple Sites with a Single Certificate":"Scenario: You have a multi-domain certificate, such as a Wildcard certificate or a SubjectAltName certificate.\nIn this case, the HTTP Server configure instructions are the same in the http domain. Two separate /etc/nginx/conf.d/, configuration files are needed, one for each site which is secured by credentials. In it, the IP address of each site with the listen directive needs to be specified. If you have two different websites with different IPs, you don’t want to use default_server .\nThe sites abc1.com, abc2.com, and /root/certs/abc.com/ are provided by the same certificate and key.\nserver { listen 203.0.113.30:ssl; listen [2001:DB8::5]:ssl; server_name abc1.com www.abc1.com; root /var/www/abc1.com; } server { listen 203.0.113.30:ssl; listen [2001:DB8::5]:ssl; server_name abc2.com www.abc2.com; root /var/www/abc1.com; } 2. Reload the configurations:\nnginx -s reload 3. HTTPS should now be accessible for both sites. You can see that the cert that supports both sites uses your browser to inform certificate property.","configure-multiple-sites-with-different-ssl-certificates#Configure Multiple Sites with Different SSL Certificates":"Scenario: You have two, or more, totally independent TLS certificate/key pairs websites that you want to serve on.\n1. Make sure that your storage certificate is well ordered. An example is given below:\n/root/certs/ ├── abc1.com/ │ ├── abc1.com.crt │ └── abc1.com.key └── abc2.com/ ├── abc2.com.crt └── abc2.com.key 2. Configure your nginx.conf http block as stated above but without the certificate and key locations. Instead, these are in the server block of the individual website because the positions on each site vary. The result should be:\nhttp { ssl_ciphers EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH; ssl_protocols TLSvTLSv1.TLSv1.2; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; } 3. Add to each server block the ssl_certificate and ssl_certificate_key directive with the proper path of the certificate and key file at each domain .\nserver { listen 203.0.113.55:ssl; listen [2001:DB8::7]:ssl; server_name example1.com www.abc1.com; root /var/www/abc1.com; ssl_certificate /root/certs/abc.com/abc1.com.crt; ssl_certificate_key /root/certs/abc.com/abc1.com.key; }\nserver { listen 203.0.113.65:ssl; listen [2001:DB8::8]:ssl; server_name example2.com www.abc2.com; root /var/www/abc2.com; ssl_certificate /root/certs/abc2.com/abc.com.crt; ssl_certificate_key /root/certs/abc2.com/abc.com.key; }\n4. Reload your configuration:\nnginx -s reload 5. Both sites should be HTTPS-accessible, but by inspecting the certificates using your browser, abc1.com uses abc1.com.crt and abc2.com usesabc2.com.crt.\nThankyou","configure-the-http-block#Configure the http Block":"Guidelines to extend NGINX to all web domains, like SSL / TLS instructions, would go to the http block in nginx.conf, The following instructions presume the same certificate and key for a particular website or all pages on the list.\nhttp { ssl_certificate /root/certs/abc.com/abc.com.crt; ssl_certificate_key /root/certs/abc.com/abc.com.key; ssl_ciphers EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH; ssl_protocols TLSv1.TLSv1.2; ","credentials-storage-location#Credentials Storage Location":"No official or favorite place to store the TLS certificate and the key on your site is safe. The certificate is sent to each server computer, and it is not a private file. The secret is private, however.\nYou want them to remain untouched and safe against other device users, wherever you want to store your certificate / key pair. We’re going to save them as an example in /root/certs/ , but you can save that folder whatever place you want.\n1. Create storage folder:\nmkdir /root/certs/abc.com/ 2. Shift into that folder your certificate(s) and key(s).\n3. Limit the following file permissions:\nchmod 400 /root/certs/abc.com/abc.com.key "},"title":"NGINX - TLS/HTTPS"},"/docs/web-servers/nginx-installation-and-basic-setup/":{"data":{"":"","before-you-begin#Before You Begin":" You need root access of the server or a sudo privileged user account. Set the hostname of your cloud server. Update your server. ","binary-versus-compiling-from-source#Binary Versus Compiling from Source":"Below are the three ways to install NGINX Open Source are available:\nA pre-built binary from your Linux distribution’s repositories. This is the best way to install because you can install the nginx package using your package manager. However, for distributions that supply binaries, you are going to run an older version of NGINX as opposed to the current stable or mainline version. Patches can also be slower to land in upstream distro repositories.\nA pre-built binary from NGINX Inc.’s repository. That is the way that sequence is built. It is still a simple installation process that just needs to be connected to your device and then configured as usual. The most beneficial approach is the traditional upstream setup with quicker updates and new releases than a Linux distribution. Compile time options are commonly different from NGINX binaries in distribution repositories and nginx -V can be used to display the built-in of your binary.\nCompiling from source. It is the most complex, but not yet impractical deployment approach after the NGINX documentation. Source code is always modified by patches and maintained on the newest stable or mainline updates, so construction can be automated easily. This is the most flexible installation method because any compiling options and flags you select can be included or skipped. For instance, one common reason why people compile their own NGINX build is that they can use a server with a newer OpenSSL version than their Linux distribution.","configuration-notes#Configuration Notes":"As the use of the NGINX web server has grown, NGINX, Inc. has worked to distance NGINX from configurations and terminology that were used in the past when trying to ease adoption for people already accustomed to Apache.\nIf you know Apache well, you will know that multiple site configurations are stored in /etc/apache/sites-available/, (so called virtual hosts in Apache terminology), which are symlinked to files inside /etc/apache/sites-enabled/. However, multiple NGINX guides and blog posts recommend the same settings. As you might expect, that lead to some confusion, with the hypothesis that NGINX uses the ../sites-available/ and ../sites-enabled/ and users of www-data regularly. That’s not the case.\nSure, it may. The NGINX packages of deposits in Debian and Ubuntu have modified their configuration for quite a while to that purpose, so it is definitely a working configuration to support sites that are stored in /sites-available/ and symlinked with /sites-enabled/. But, it’s unnecessary and the only one that does it is the Debian Linux family. Do not push Apache settings on NGINX.\nMultiple site configuration files can then be stored as an abc.com.conf, or abc.com.disabled in /etc/nginx/conf.d/. Do not add server blocks to /etc/nginx/nginx.conf directly, as your configuration is fairly straightforward. This file is intended to configure the server process rather than individual websites.\nThe NGINX method also acts as the ngnix user in the nginx community, so note when you change permissions to website folders. See Creating NGNIX Plus Configuration Files .\nUltimately, as the NGINX docs point out, Virtual Host is an Apache concept, even though it is used in the Debian and Ubuntu file nginx.conf and some of the old documentation of NGINX. The NGINX equivalent is a Server Block, so this is the phrase you will see on NGINX in this show.","configuration-recap#Configuration Recap":"To summarize where we have been so far:\nThe stable version of NGINX Open Source has been installed from the nginx.org repository. A basic website can be accessed: The root directory is located in /var/www/example.com/\nThe configuration file is located in /etc/nginx/conf.d/abc.com.conf.\nserver { listen default_server; listen [::]:default_server; server_name abc.com www.abc.com; root /var/www/abc.com; index index.html; gzip on; gzip_comp_level 3; gzip_types text/plain text/css application/javascript image/\\*; } Changes that we want NGINX to apply universally are in the /etc/nginx/nginx.conf http block. Our additions are at the bottom of the block, so we know what’s added compared to what’s provided by default. Now, nginx.conf looks like the following example. Please note that nginx.conf does not contain any server blocks:\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main ‘$remote_addr - $remote_user [$time_local] “$request” ' ‘$status $body_bytes_sent “$http_referer” ' ‘\"$http_user_agent\" “$http_x_forwarded_for”’;\naccess_log /var/log/nginx/access.log main;\nsendfile on; #tcp_nopush on;\nkeepalive_timeout 65;\n#gzip on;\ninclude /etc/nginx/conf.d/*.conf;\nserver_tokens off;\n} Thankyou…","disable-server-tokens#Disable Server Tokens":"The version number of NGINX is available by default when the server is linked, whether by good 201 curl or 404 returned to a client. Disabling server tokens makes it harder to evaluate versions of NGINX and hence harder for an attacker to execute version-specific attacks.\nServer tokens enabled:\nServer tokens disabled:\nAdd the below line to the http block of /etc/nginx/nginx.conf:\nserver_tokens off; ","install-nginx#Install NGINX":"","installation-instructions#Installation Instructions":"The NGINX admin guide provides simple and specific instructions for any installation method and version of NGINX you like, so we won’t represent it here. When your installation is done, return to the show.","nginx-configuration-best-practices#NGINX Configuration Best Practices":"There are a wide variety of tweaks to NGINX to best suit your needs. Nonetheless, others are unique to your use; what works well for one person can not work for another.\nThis series provides configurations that are fairly generic for use in almost any production scenario, but on which you can create for your own specialized setup. None of the following is considered best practice, and none of them are mutually related. They are not necessary to the operation of your site or server, but unintended and unwanted effects if they are not taken into account.\nTwo short points:\nFirst preserve your default nginx.conf file so that you have something to recover if your personalization is so difficult that NGINX breaks. ``` cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.backup-original - After applying the following update, reload your configuration with: ``` nginx -s reload ","serve-content-over-ipv4-and-ipv6#Serve Content Over IPv4 and IPv6":"Add a second IPv6 listen Directive to the /etc/nginx/conf.d/abc.com.conf: server block:\nlisten [::]:80; If your site is using SSL/TLS, you would add:\nlisten [::]:443 ssl; ","set-your-sites-root-directory#Set Your Site’s Root Directory":"The NGINX directory serves sites that vary depending on how you have installed them. NGINX supplied from NGINX Inc. uses /usr/share/nginx/ at the time of this writing.\nNGINX docs warn of the loss of site data when upgrading NGINX by depending on the default location .. You can use /var/www/,/srv/, or any other location where package or device updates are not affected . See Using the default document root and Not using standard document root locations.\nThe /var/www/abc.com/ sequence will be used in its examples. Replace abc.com , which can be accessed with your Cloud server’s IP address or domain name.\n1. The root directory of your site or sites should be linked to /etc/nginx/conf.d/abc.com.conf corresponding server block:\nroot /var/www/abc.com; 2. Then make that directory:\nmkdir -p /var/www/abc.com ","stable-versus-mainline#Stable Versus Mainline":"The first decision on your installation is whether you want NGINX Open Source stable or mainline version. Stable is recommended and what this set of guides uses should be. Information on NGINX here.","static-content-compression#Static Content Compression":"You do not want to uniformly allow gzip compression because you run the risk of vulnerability to the CRIME and BREACH exploits depending on the content and session cookies.\nIn NGINX compression has been disabled for years now by default, so that it is not vulnerable out of the box to CRIME. Modern browsers have also taken steps to combat these attacks, but web servers may be irresponsibly configured.\nAt the other hand, if you completely disable gzip compression, you remove such vulnerabilities and use less CPU cycles at the cost of reducing the efficiency of the web. Different mitigations are possible on the server and the introduction of TLS 1.3 will contribute further to this. For now, the only way, unless you know what you are doing, is only to compress static site content like images, Text, and CSS.\nBelow is an example of how to use cat /etc/nginx/mime.types to display the mime forms available. If you want the gzip guidelines to extend to all sites supported by NGINX in the http domain, it is better to use them for specific sites and content types only in the server domain.\ngzip on; gzip_types text/html text/plain text/css image/*; If NGINX serves many websites, some use SSl / TLS and some don’t, an example would look as in the following example. The gzip directive is applied to the server block of the HTTP site to keep it disabled for the HTTPS domain.\nserver { listen 80; server_name example1.com; gzip on; gzip_types text/html text/css image/jpg image/jpeg image/png image/svg; } server { listen ssl; server_name example2.com; gzip off; } There are several other options available for the gzip module of NGINX. See NGINX docs for more detail, and you can also use the ngx http gzip static module which suits static content compression if you want to compile NGINX builds.","use-multiple-worker-processes#Use Multiple Worker Processes":"Add or edit the below line in /etc/nginx/nginx.conf, in the area just before the http block. This is the called main block, or context, though it’s not marked in nginx.conf like the http block is. The first choice would be to set it to auto, or the amount of CPU cores available to your cloud server.\nworker_processes auto; For more details, see the sections on worker processes in the NGINX docs and this NGINX blog post."},"title":"NGINX - Setup"},"/docs/web-servers/use-nginx-as-a-reverse-proxy/":{"data":{"":"A reverse proxy is a server between internal and external clients which transmits clients requests to a different server. Although other standard applications, such as Node.js, can support themselves, NGINX has a range of advanced load balancing, safety and speed features that most specialized applications do not have. The reverse proxy of NGINX helps you to apply these functions to any program.\nA simple Node.js app to illustrate how to configure NGINX as reverse proxy is used for this tutorial.","advanced-options#Advanced Options":"The proxy_pass directive is enough for a simple application. More complex apps can however require additional guidance. For instance, Node.js is often used for applications that involve several real-time interactions. Disable NGINX buffering feature to accommodate:\nlocation / { proxy_pass http://localhost:3000/; proxy_buffering off; } You may also modify or delete the headers forwarded with the proxy_set_header request:\nlocation / { proxy_pass http://localhost:3000/; proxy_set_header X-Real-IP $remote_addr; } This configuration uses the $remote_addr variable to give the original client IP address to the proxy host.","basic-configuration-for-nginx-reverse-proxy#Basic Configuration for NGINX Reverse Proxy":"1. Create a configuration file for the app in /etc/nginx/conf.d/. Replace abc.com into your app’s domain or public IP address:\nserver { listen 80; listen [::]:80; server_name abc.com; location / { proxy_pass http://localhost:3000/; b } } This setup is a reverse proxy through the proxy_pass command. It specifies to forward to port 3000 on locals all applications corresponding to the location block (in this case, the root / path) on the localhost, where the Node.js application is running.\n2. Disable or delete default Welcome to NGINX page:\nsudo mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.disabled 3. Test the configuration:\nsudo nginx -t 4. Reload the new configuration if no errors are reported:\nsudo nginx -s reload 5. In a browser, navigate your cloud server’s public IP address. Now it should be show the “Microhost cloud” message displayed.","configure-https-with-certbot#Configure HTTPS with Certbot":"A reverse proxy has the advantage that HTTPS can easily be set up with a TLS certificate. Certbot is a device that enables you to get free Let’s Encrypt certificates quickly. On Ubuntu 16.04 this guide is going to use Certbot, but the official website holds complete installation and guidance for all major districts.\nUse below these steps to receive a Certbot certificate. In order to use the new certificate, Certbot automatically updates your NGINX settings files:\n1. Install the Certbot and internet server-specific packages, then run Certbot:\nsudo apt-get update sudo apt-get install software-properties-common sudo add-apt-repository ppa:certbot/certbot sudo apt-get update sudo apt-get install python-certbot-nginx sudo certbot --nginx 2. Certbot is going to ask for website details. As part of the certificate, the answer will be saved:\n# sudo certbot --nginx Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator nginx, Installer nginx What names do you want HTTPS allowed for? 1: abc.com 2: www.abc.com Select the correct commas and/or spaces separated numbers, or leave the input Select all of the choices displayed blankly (Enter ' c ' to cancel): 3. Certbot will also ask if you would like to routinely redirect HTTP visitors to HTTPS visitors. It is suggested that you choose this option.\n4. Once the tool is completed, Certbot will store all of the created keys and certificates into/etc/letsencrypt/live/$domain , where $domain is the name of the domain entered during the generation stage of the certificate.\nNote:- Certbot recommends pointing your web server configuration to the default certificate directory or creating symlinks. Keys and certificate should not be moved to a special directory.\nFinally, Certbot will replace your internet server configuration in order that it makes use of the new certificate, and also redirects HTTP visitors to HTTPS if you selected that option.\n5. If you’ve a firewall configured on your Cloud server, you need to add a firewall rule to allow incoming and outgoing connections to the HTTPS service. On Ubuntu, UFW is a commonly used and simple tool for handling firewall rules. for HTTP and HTTPS traffic Install and configure UFW:\n# sudo apt install ufw sudo systemctl start ufw sudo systemctl enable ufw sudo ufw allow http sudo ufw allow https sudo ufw enable Thankyou…….","configure-nginx#Configure NGINX":"You can configure Node.js to use a sample app on the public IP address of your cloud server to view the device on the internet. This segment then configures NGINX such that all requests from the public IP address are forwarded to the server on localhost already listening.","configure-the-app#Configure the App":"1. Make a directory for the example app:\nmkdir nodeapp \u0026\u0026 cd nodeapp 2. Initialize a Node.js app within the directory:\nnpm init Accept all the defaults when prompted.\n3. Install Express.js:\nnpm install --save express 4. Use a text editor to create app.js and add the below content:\nconst express = require('express') const app = express() app.get('/', (req, res) =\u003e res.send('Microhost Cloud!')) app.listen(3000, () =\u003e console.log('Node.js app listening on port 3000.')) 7 5. Run the app:\nnode app.js 6. In a new terminal window, use curl to verify that the app is working on localhost\ncurl localhost:3000 Microhost Cloud! ","create-an-example-app#Create an Example App":"Install Node.js 1. Using curl to access the NodeSource installation file. Replace the version of the node with the version you want to install in the curl command:\ncurl -sL https://deb.nodesource.com/setup_9.x -o nodesource_setup.sh 2. Run the script:\nsudo bash nodesource_setup.sh 3. The setup script will run an apt-get update it automatically, so you can install Node.js right away:\nsudo apt install nodejs npm Next to Node.js will be installed the Node Package Manager (NPM).","install-nginx#Install NGINX":"These measures are used to install NGINX Mainline from the official NGINX Inc repository on Ubuntu. See the NGINX admin guide for other distributions. See our Getting Started with the NGINX series for information about configuring NGINX for production environments.\n1. In the text editor, Open /etc/apt/sources.list and add the next line to the right. Substitute CODENAME by your Ubuntu release codename in this case. For eg, the bionic insert in place of CODENAME below for Ubuntu 18.04 named bionic Beaver:\ndeb http://nginx.org/packages/mainline/ubuntu/ CODENAME nginx 2. Import the signing key for the repository and link it to apt:\nsudo wget http://nginx.org/keys/nginx_signing.key sudo apt-key add nginx_signing.key 3. Install NGINX:\nsudo apt update sudo apt install nginx 4. Ensure that NGINX works and can automatically continue when reboot:\nsudo systemctl start nginx sudo systemctl enable nginx "},"title":"NGINX - Reverse Proxy"},"/docs/windows/how-to-add-ssl-biniding-in-windows-server/":{"data":{"":"\nStep 1. Bind the certificate.\nOpen bindings options in default web sites. As shown in the below screenshot .\nClick on “Bindings…”\nStep 2 : After opening the bindings , Click on add/edit option to add the domains for the SSL\nAdd a new rule.\nOr edit the existing rule. Step 3: Choose the type, IP, port, and SSL certificate and then click on OK.\nSSL has been successfully installed on the domain , Please verify through URL .\nThank you."},"title":"How to add SSL biniding in windows server"},"/docs/windows/how-to-allocate-unallocated-disk-space-in-windows/":{"data":{"":"\nIntroduction Unallocated space, also referred to as “free space,” is the area on a hard drive where new files can be stored. Conversely, allocated space is the area on a hard drive where files already reside. Think of “allocated” storage space as already filled with data and not to be overwritten with other newer data, while “unallocated” space is available to store new data even though it may contain old data which would be overwritten by new data. In this blog, we will how to allocate unallocated disk space in Windows Server.\nStep 1. Login to your Windows server\nStep 2. Open Command Prompt (cmd)\nStep 3. run diskpart\nC:UsersAdministrator\u003ediskpart Step 4. run list volume\nDISKPART\u003e list volume Step 5. run select volume 0\nDISKPART\u003e select volume 0 Step 6. run extend filesystem allocate unallocated disk space\nDISKPART\u003e extend filesystem Disk Allocation: Successful\nHow to add additional storage to your server.\nThank You!"},"title":"How to allocate unallocated disk space in Windows Server"},"/docs/windows/how-to-allow-icmpv4ping-in-windows-firewall-using-powershell/":{"data":{"":"","introduction#INTRODUCTION":"ICMPv4 Internet Control Message Protocol version 4 is definitely a Network layer protocol. And its job is to report the error to the source if any problem arises while delivering the datagram. The ICMPv4 is a message-oriented protocol. It’s a protocol of version 4 of the TCP/IP protocol suite. In this article we will learn How to allow ICMPv4(PING) in Windows Firewall using Powershell.\nStep 1. Open PowerShell and an Administrator allow ICMPv4(PING) in Windows Step 2. Run the command to add rule of ICMPv4 Step 3. Set a display Name open ICMPv4(PING) in Windows A Step 4. Check if the rule is properly added.\nRule added successfully.\nThank You!"},"title":"How to allow ICMPv4(PING) in Windows Firewall using PowerShell"},"/docs/windows/how-to-allow-multiple-rdp-sessions-for-the-single-user-in-windows-server/":{"data":{"":"\nStep 1. Login to your windows server\nStep 2. Launch the Registry Editor in Windows Server, go to Start and then Run. Type regedit in run menu and hit enter. To launch Registry Editor in Windows Server 2012 R2, press Windows key + R. Type regedit in run menu and hit enter.\nStep 3. Once Registry Editor window is launched, navigate to HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TerminalServer.\nStep 4. By selecting the Terminal Server registry, you would see the registry key fSingleSessionPerUser on the right panel.\nStep 5. Right-click on fSingleSessionPerUser key and then click on Modify. Step 6. Change the key value from 1 to 0 as shown in the screenshot below, and close the Registry Editor. The value 1 denotes single session for each remote desktop user, and 0 denotes multiple sessions for each user.\nMultiple RDP sessions for the single user enabled.\nNote:\nIf fSingleSessionPerUser key is not available then you will need to create it manually. To add a new key, click on Terminal Server \u003e\u003e New \u003e\u003e New DWORD (32) Value. Name this key as fSingleSessionPerUser, set its value to 0 and close the Registry Editor.\nThank You."},"title":"How to allow multiple RDP sessions for the single user in Windows Server"},"/docs/windows/how-to-block-or-allow-tcp-ip-port-in-windows-firewall/":{"data":{"":"","allow-port-in-firewall#Allow port in Firewall":"Step 1. Navigate to the Windows Firewall and advanced settings.\nStep 2. To see the list of rules, select “Inbound Rules” from the menu that appears on the left side of the window. then click on the new rule.\nStep 3. Select port and then press the next button. Step 4. Click on “Specific local ports” and choose a port number (e.g., 80). then click on “next.”\nStep 5. Choose Allow the Connection and then click Next. Step 6. Apply Your New Rule to Each of the Different Types of Profiles. To apply your rule to each of the three kinds of profiles (domain, private, and public), under the Profile window, you must check the appropriate boxes. To proceed, click the “Next” button.\nStep 7. Give your new rule a name. You can also add a description to your rule if you want to. Click “Finish” when you’re done to set up the settings.","block-port-in-firewall#Block port in Firewall":"Step 1. Navigate to the Windows Firewall and advanced settings.\nStep 2. To see the list of rules, select “Inbound Rules” from the menu that appears on the left side of the window. then click on the new rule.\nStep 3. Select port and then press the next button. Step 4. Click on “Specific local ports” and choose a port number (e.g., 80). then click on “next.”\nStep 5. Choose Block the Connection and then click Next. Step 6. Apply Your New Rule to Each of the Different Types of Profiles. To apply your rule to each of the three kinds of profiles (domain, private, and public), under the Profile window, you must check the appropriate boxes. To proceed, click the “Next” button.\nStep 7. Give your new rule a name. You can also add a description to your rule if you want to. Click “Finish” when you’re done to set up the settings.","conclusion#Conclusion":"Hopefully, you have learned how to block or allow ports in windows firewall.\nThank You 🙂","introduction#Introduction":"In this article, you will learn how to block or allow ports in windows firewall.\nYour Windows machine can be protected from any threats posed by the network by using the Windows Firewall. You have the option of controlling who is granted to enter your system as well as the level of accessibility that is granted."},"title":"How to Block or Allow TCP/IP Port in Windows Firewall"},"/docs/windows/how-to-boot-windows-server-2012-into-safe-mode/":{"data":{"":"","conclusion#Conclusion":"Hopefully, you have learned how to boot windows server into safe mode.\nAlso read: How to Install OpenSSH on Windows Server\nThank You 🙂","introduction#Introduction":"In this article, you will learn how to boot windows server into safe mode.\nSafe Mode is an unique Windows boot-up mode that can be used to restart the computer once a major problem has occurred that interferes with normal Windows functions and activities. Safe Mode enables users to debug and find the root cause of a fault.\nIn safe mode, an operating system has reduced functionality; however, the process of isolating problems is facilitated by the fact that many non-essential components, such as sound, are disabled. An installation that will only boot into safe mode typically has a significant issue, such as disc corruption or the installation of software with improper configuration, which prevents the operating system from successfully booting into its normal operating mode and allowing the user to use the computer as intended.\nA user is normally granted access to utility and diagnostic programs when operating in safe mode. This enables the user to investigate and resolve issues that prevent the operating system from functioning normally. The functionality of the system is not meant to be used while in safe mode, and user access to features is severely restricted.\nYou have to login into your window server.\nStep 1. On the right side of the window, search cmd and click on Command Prompt.\nStep 2. Now run the msconfig command.\n# msconfig Step 3. Now click Left on the boot option, which is next to the general.\nStep 4. Go to the Boot menu, and then choose “Safe boot” from the list of “Boot settings.”\nStep 5. After pressing OK, the below screenshot will show on your screen. Select the Restart option to apply the changes.\nStep 7. After selecting Restart, you have to log into your server again and you will see a black screen on your server. That means your server is now in safe mode."},"title":"How to Boot Windows Server into Safe Mode"},"/docs/windows/how-to-change-default-shell-from-cmd-to-powershell-in-windows-server/":{"data":{"":"\nFollow these steps to change default shell from cmd to PowerShell in the following article..\nStep 1. Login to your Windows Server.\nStep 2. Start PowerShell as Administrator on the OpenSSH server and run the following command:\nGet-Command powershell | Format-Table -AutoSize -Wrap CommandType Name Version Source\n-————- —— ——- ——\nApplication powershell.exe 10.0.17763.1 C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\nStep 3. Set DefaultShell=PowerShell in the OpenSSH registry entry. PowerShell PATH specifies the PATH confirmed above\nNew-ItemProperty -Path \"HKLM:SOFTWAREOpenSSH\" -Name DefaultShell -Value \"C:WindowsSystem32WindowsPowerShellv1.0powershell.exe\" -PropertyType String -Force DefaultShell : C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\nPSPath : Microsoft.PowerShell.Core\\Registry::HKEY_LOCAL_MACHINE\\SOFTWARE\\OpenSSH\nPSParentPath : Microsoft.PowerShell.Core\\Registry::HKEY_LOCAL_MACHINE\\SOFTWARE\nPSChildName : OpenSSH\nPS Drive : HKLM\nPSProvider : Microsoft.PowerShell.Core\\Registry\nSo, this is how you can change default shell from cmd to PowerShell in Windows Server.\nThank You!"},"title":"How to change default shell from cmd to PowerShell in Windows Server"},"/docs/windows/how-to-change-rdp-port-in-windows-support-internal/":{"data":{"":"\nStep1 :: Need to connect windows server with Administrator privilege, then type below command in search box “regedit”\nStep2 :: You need to follow the below path to change the RDP Port in the Windows system.\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\nStep3 ::After following above path steps, need to right click on on port number then provide the wanted port number for connection.\nStep4 :: Need to follow below steps to change the port number in registry.\nNow give your desired port number to connect to the windows server…\nStep5 :: Now I need to exit the registry then reboot the server to see the changes on it.\nStep6 :: Now we have to check the server connection with the new RDP port.\nThanks :)"},"title":"How to change RDP port in Windows Server"},"/docs/windows/how-to-change-rdp-port-via-powershell-in-windows-server/":{"data":{"":"","conclusion#Conclusion":"Hopefully, now you have learned how to change RDP port via PowerShell in Windows server.\nAlso read: How to Block or Allow TCP/IP Port in Windows Firewall\nThank You 🙂","introduction#Introduction":"In this article, you will learn how to change RDP port via PowerShell in Windows server.\nThe Remote Desktop Protocol, also known as RDP, is a proprietary protocol developed by Microsoft that enables users to remotely connect to other computers, most commonly through TCP port 3389. A distant user can gain access to the network using its encrypted communication channel.\nThe Windows Remote Desktop (RDP) port 3389 is a popular target for hackers. So, it may make sense to alter the RDP port. This article describes how to change RDP port via PowerShell in Windows server 2012/2016/2019.\nStep 1. In the search box, type PowerShell.\nStep 2. Run PowerShell as an administrator.\nStep 3. To determine the current RDP port, use the command below. # Get-ItemProperty -Path 'HKLM:\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Terminal Server\\\\WinStations\\\\RDP-Tcp' -name \"PortNumber\" Step 4. To change the RDP port, run the below command and change the port as per your own.\n# Set-ItemProperty -Path 'HKLM:\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Terminal Server\\\\WinStations\\\\RDP-Tcp' -name \"PortNumber\" -Value $portvalue=new\\_port\\_number Step 5. Run the below command to check the newly set RDP port.\n# Get-ItemProperty -Path 'HKLM:\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Terminal Server\\\\WinStations\\\\RDP-Tcp' -name \"PortNumber\" Step 6. To reflect the changes, restart the RDP services from the Task Manager."},"title":"How to change RDP port via PowerShell in Windows server"}}